{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-05-23 13:07:23.731928: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-23 13:07:23.776000: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils.vector_metrics' from '/home/ubuntu/brianna-chrisman/MATS-2024/utils/vector_metrics.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install einops transformers sae_lens sae_vis\n",
    "import einops\n",
    "import os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes, convert_connor_rob_sae_to_our_saelens_format, download_sae_from_hf\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import plotly_express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "from torch.utils.data import Dataset\n",
    "from sae_vis.model_fns import AutoEncoderConfig, AutoEncoder\n",
    "from transformer_lens import utils as tl_utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")\n",
    "\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "from transformer_lens.utils import (\n",
    "    load_dataset,\n",
    "    tokenize_and_concatenate,\n",
    "    download_file_from_hf,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "from transformer_lens import HookedSAE, HookedSAEConfig\n",
    "from transformer_lens.utils import download_file_from_hf\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "from utils.autoencoder import AutoEncoder\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.colormaps[\"Spectral\"]\n",
    "\n",
    "from utils import SAE_metrics\n",
    "from utils import vector_metrics\n",
    "from utils import utils \n",
    "\n",
    "\n",
    "import torch \n",
    "reload(utils)\n",
    "reload(SAE_metrics)\n",
    "reload(vector_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SAE & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_name': 'blocks.1.attn.hook_z',\n",
      " 'act_size': 512,\n",
      " 'anthropic_resample_last': 25000,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'concat_heads': True,\n",
      " 'dead_direction_cutoff': 1e-07,\n",
      " 'device': 'cuda',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'head': 'cat',\n",
      " 'l1_coeff': 2.0,\n",
      " 'layer': 1,\n",
      " 'lr': 0.001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'name': 'gelu-2l_1_16384_z',\n",
      " 'num_resamples': 4,\n",
      " 'num_tokens': 2000000000,\n",
      " 're_init_every': 50000,\n",
      " 'reinit': 'reinit',\n",
      " 'resample_factor': 0.01,\n",
      " 'save_state_dict_every': 50000,\n",
      " 'seed': 49,\n",
      " 'seq_len': 128,\n",
      " 'site': 'z',\n",
      " 'wandb_entity': 'ckkissane',\n",
      " 'wandb_project_name': 'concat-z-gelu-21-l1-lr-sweep-3'}\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "auto_encoder_run = \"concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78\"\n",
    "sae = AutoEncoder.load_from_hf(auto_encoder_run)\n",
    "model = HookedTransformer.from_pretrained(\"gelu-2l\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1365, 0.1563, 0.1192,  ..., 0.1673, 0.0468, 0.1531],\n",
       "        [0.0560, 0.3308, 0.1041,  ..., 0.0830, 0.0554, 0.1194],\n",
       "        [0.4276, 0.0736, 0.1790,  ..., 0.1209, 0.0434, 0.1782],\n",
       "        ...,\n",
       "        [0.0874, 0.0992, 0.1020,  ..., 0.0821, 0.0469, 0.1132],\n",
       "        [0.0224, 0.0681, 0.0429,  ..., 0.0153, 0.6039, 0.0863],\n",
       "        [0.1716, 0.0837, 0.1612,  ..., 0.4079, 0.0374, 0.1248]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split tensor into 8 equal parts\n",
    "W_dec_splits = torch.split(sae.W_dec, model.cfg.d_head, dim=1)\n",
    "# Turn list of tensors into a single tensor, add dimension\n",
    "W_dec_splits = torch.stack(W_dec_splits, dim=0)\n",
    "contributions = W_dec_splits.norm(dim=2)\n",
    "contributions = contributions/contributions.sum(dim=0, keepdim=True)\n",
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(contributions.max(dim=0).values.cpu().detach().numpy(), bins=100)\n",
    "plt.xlabel('Max contribution from an individual head')\n",
    "plt.ylabel('Number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b0f5f98f2048d7aae3215e5865e6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Pile data\n",
    "data = load_dataset(\"NeelNanda/pile-10k\", split=\"train[:1000]\")\n",
    "tokenized_data = tokenize_and_concatenate(data, model.tokenizer, max_length=32)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "all_tokens = tokenized_data[\"tokens\"][:1024]\n",
    "\n",
    "dataset = utils.TokenDataset(all_tokens)\n",
    "del tokenized_data, data, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Load LLM and SAE\n",
    "model = HookedTransformer.from_pretrained(\"gelu-2l\").to(device)\n",
    "#hook_points = [h.replace('attn.hook_z', 'hook_resid_pre') for h in gpt2_sae.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0059, device='cuda:0')\n",
      "tensor(0.0402, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, _, acts, _ , _ = sae.forward(t.rand(sae.W_enc.shape[0]).to(device))\n",
    "acts2 = t.rand(sae.W_enc.shape[0]).to(device) @ sae.W_enc + sae.b_enc\n",
    "print((acts>0).float().mean())\n",
    "print((acts2>0).float().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.b_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Activation Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.b_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [64, 32, 1, 16384] at index 2 does not match the shape of the indexed tensor [64, 32, 8, 16384] at index 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15382/591881022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     model.run_with_hooks(\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# For efficiency, we don't need to calculate the logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mrun_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfwd_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwd_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_hooks_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_contexts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhooked_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhooked_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     def add_caching_hooks(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    548\u001b[0m                     )\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1586\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_z_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, pos, head_index, d_head]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attn_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_in_4bit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mcalculate_z_scores\u001b[0;34m(self, v, pattern)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch head_index query_pos key_pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     ) -> Float[torch.Tensor, \"batch query_pos head_index d_head\"]:\n\u001b[0;32m--> 764\u001b[0;31m         z = self.hook_z(\n\u001b[0m\u001b[1;32m    765\u001b[0m             einsum(\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1545\u001b[0m                     \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m                     \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mfull_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     75\u001b[0m             ):  # For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\n\u001b[1;32m     76\u001b[0m                 \u001b[0mmodule_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         full_hook.__name__ = (\n",
      "\u001b[0;32m/tmp/ipykernel_15382/591881022.py\u001b[0m in \u001b[0;36mSAE_hook\u001b[0;34m(activations, hook)\u001b[0m\n\u001b[1;32m     16\u001b[0m                   \"d_head n_head n_features, batch seq_len n_head d_head -> batch seq_len n_head n_features\")\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdot_prods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_prods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Append contributions to contributons_all tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcontributions_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_prods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.sum(dim=0).sum(dim=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [64, 32, 1, 16384] at index 2 does not match the shape of the indexed tensor [64, 32, 8, 16384] at index 2"
     ]
    }
   ],
   "source": [
    "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "W_enc_split = torch.split(sae.W_enc, model.cfg.d_head, dim=0)\n",
    "W_enc_split = torch.stack(W_enc_split, dim=1)\n",
    "\n",
    "b_dec_split = torch.split(sae.b_dec, model.cfg.d_head, dim=0)\n",
    "b_dec_split = torch.stack(b_dec_split, dim=1).transpose(0,1)\n",
    "# Append \n",
    "contributions_all = []\n",
    "\n",
    "def SAE_hook(\n",
    "    activations, #: torch.float[torch.Tensor, \"batch seq_len n_head d_head \"],\n",
    "    hook: HookPoint,\n",
    "):\n",
    "    dot_prods = einops.einsum(W_enc_split, activations-b_dec_split,\n",
    "                  \"d_head n_head n_features, batch seq_len n_head d_head -> batch seq_len n_head n_features\")\n",
    "    (dot_prods.sum(dim=2, keepdim=True)+sae.b_enc)>0\n",
    "\n",
    "    dot_prods[torch.where((dot_prods.sum(dim=2, keepdim=True)+ sae.b_enc)<0)] = torch.nan\n",
    "\n",
    "    # Append contributions to contributons_all tensor\n",
    "    contributions_all.append(dot_prods.to('cpu'))#.sum(dim=0).sum(dim=1))\n",
    "\n",
    "\n",
    "for tokens, i in DataLoader(dataset, batch_size=64, shuffle=True):\n",
    "    model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=None, # For efficiency, we don't need to calculate the logits\n",
    "        fwd_hooks=[(\n",
    "            sae.cfg[\"act_name\"],\n",
    "            SAE_hook\n",
    "        )]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 8, 16384])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions_all = torch.cat(contributions_all, dim=0)\n",
    "contributions_all = einops.rearrange(contributions_all, \"batch seq_len n_head n_features -> (batch seq_len) n_head n_features\")\n",
    "contributions_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1249)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions_all.isnan().float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16384])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed = (contributions_all**2).sum(dim=0)\n",
    "normed = normed/normed.sum(dim=0, keepdim=True)\n",
    "normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normed.max(dim=0).values, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = einops.rearrange(contributions_all, \"batch seq_len n_head n_features -> (batch seq_len) n_head n_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1063,  0.4432, -0.0684,  ...,  0.1140, -0.0341,  0.1621],\n",
       "        [ 0.0825,  0.4626, -0.0491,  ...,  0.1035, -0.0362,  0.1679],\n",
       "        [-0.0049,  0.6636, -0.2342,  ...,  0.0864, -0.0504,  0.1618],\n",
       "        ...,\n",
       "        [ 0.3586,  1.2482, -0.2915,  ..., -0.8665, -0.2243,  0.5441],\n",
       "        [ 0.5252,  1.8118, -0.4020,  ..., -1.5610, -0.2407,  0.7289],\n",
       "        [ 0.4821,  0.7107, -0.2438,  ..., -0.0389, -0.1549,  0.5067]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.5598e-01,  1.0626e-01,  2.2022e-01,  ...,  5.2214e-01,\n",
       "           -8.1074e-02,  1.3789e-01],\n",
       "          [-1.8468e-01,  4.4324e-01,  3.9775e-01,  ..., -5.6378e-01,\n",
       "            2.4357e-02, -1.4211e-01],\n",
       "          [ 2.7656e-01, -6.8393e-02, -7.2752e-02,  ...,  1.7196e-01,\n",
       "            3.9732e-01,  1.8549e-01],\n",
       "          ...,\n",
       "          [ 2.2754e-01,  1.1399e-01,  6.6205e-02,  ..., -2.1901e-01,\n",
       "            1.9454e-01,  1.5027e-01],\n",
       "          [-1.9198e-01, -3.4131e-02, -1.2947e-01,  ..., -1.7822e-02,\n",
       "            2.0792e-01, -6.8057e-02],\n",
       "          [ 2.4169e-01,  1.6212e-01,  2.8259e-01,  ...,  5.5884e-01,\n",
       "            2.0451e-01,  3.3795e-01]],\n",
       "\n",
       "         [[ 3.4018e-01,  8.2544e-02,  2.2621e-01,  ...,  4.1745e-01,\n",
       "           -8.3391e-03,  1.5352e-01],\n",
       "          [-2.4335e-01,  4.6264e-01,  3.1731e-01,  ..., -6.7297e-01,\n",
       "            6.6912e-02, -8.3786e-02],\n",
       "          [-1.4347e-01, -4.9074e-02,  7.4916e-02,  ...,  1.6964e-01,\n",
       "            1.9603e-01,  3.7283e-01],\n",
       "          ...,\n",
       "          [ 3.3206e-01,  1.0347e-01,  3.6806e-02,  ..., -1.0319e-01,\n",
       "            2.3510e-01,  8.2624e-02],\n",
       "          [-2.5845e-01, -3.6184e-02, -1.0428e-01,  ..., -2.3059e-02,\n",
       "            2.5885e-01, -5.2631e-02],\n",
       "          [ 3.8457e-01,  1.6792e-01,  2.4377e-01,  ...,  6.0065e-01,\n",
       "            1.6820e-01,  1.5890e-01]],\n",
       "\n",
       "         [[-1.3035e-02, -4.9123e-03,  4.5232e-01,  ...,  2.3029e-01,\n",
       "            1.0977e-01,  6.8080e-01],\n",
       "          [-1.0193e-01,  6.6361e-01,  4.6997e-01,  ...,  1.5528e+00,\n",
       "            1.8495e-01, -1.5225e-01],\n",
       "          [ 6.0188e-01, -2.3416e-01, -3.7328e-01,  ...,  5.1321e-01,\n",
       "           -1.3321e+00, -2.5685e-01],\n",
       "          ...,\n",
       "          [ 1.1593e-01,  8.6381e-02, -1.9762e-02,  ..., -2.0429e-01,\n",
       "            5.3026e-01,  6.3447e-02],\n",
       "          [-1.0691e-01, -5.0363e-02, -1.4374e-01,  ...,  4.8221e-02,\n",
       "            6.9816e-01, -9.0631e-02],\n",
       "          [ 2.3081e-01,  1.6185e-01,  2.7908e-01,  ...,  1.9016e-01,\n",
       "            5.6008e-01,  2.1756e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4479e-01, -4.3798e-02,  1.0952e-02,  ..., -1.1162e+00,\n",
       "           -6.8466e-02,  1.3702e+00],\n",
       "          [-2.1894e-01,  1.0540e+00,  7.2326e-01,  ..., -3.6534e+00,\n",
       "            2.2235e-02, -1.0055e+00],\n",
       "          [ 2.6093e-01, -3.8318e-01, -3.0398e-01,  ...,  3.3765e-01,\n",
       "            3.8377e-01, -2.8483e+00],\n",
       "          ...,\n",
       "          [ 1.9921e-01,  2.2030e-01, -9.9907e-02,  ...,  2.4721e+00,\n",
       "            1.5877e-01, -4.3290e-02],\n",
       "          [-1.9224e-01, -1.1327e-01, -2.5517e-01,  ..., -2.9534e-01,\n",
       "            1.6141e-01, -5.6334e-01],\n",
       "          [ 3.0686e-01,  1.1859e-01,  5.3269e-01,  ..., -6.5071e-01,\n",
       "            1.7462e-01,  1.1520e+00]],\n",
       "\n",
       "         [[ 3.6707e-01, -8.4544e-02, -5.1458e-02,  ..., -2.7068e-01,\n",
       "            1.6060e-03,  3.9456e-01],\n",
       "          [-3.3292e-01,  1.6937e+00,  5.4344e-01,  ..., -1.2517e+00,\n",
       "            3.5888e-02, -3.5399e-02],\n",
       "          [ 9.5542e-02, -7.9328e-01,  2.3198e-02,  ...,  1.0779e+00,\n",
       "            5.2017e-01,  6.0147e-01],\n",
       "          ...,\n",
       "          [ 2.7732e-01,  1.2798e-01, -4.0648e-02,  ...,  4.0988e-01,\n",
       "            1.2678e-01, -8.8192e-02],\n",
       "          [-2.3927e-01, -1.2118e-01, -1.6389e-01,  ..., -6.7645e-02,\n",
       "            1.8849e-01, -7.8665e-02],\n",
       "          [ 2.9450e-01, -1.3242e-03,  3.7890e-01,  ..., -6.2185e-01,\n",
       "            7.0898e-02, -5.6753e-02]],\n",
       "\n",
       "         [[ 2.5673e-01, -2.2431e-02,  7.7767e-02,  ..., -1.1547e-01,\n",
       "           -1.8432e-01, -2.7909e+00],\n",
       "          [-2.0977e-01,  7.6145e-01,  4.3082e-01,  ..., -9.2651e-01,\n",
       "            2.5762e-02,  6.5763e-01],\n",
       "          [ 2.9404e-01, -4.4810e-02,  7.9783e-02,  ...,  2.6781e-01,\n",
       "            3.5431e-01,  3.8039e+00],\n",
       "          ...,\n",
       "          [ 2.2960e-01,  1.3017e-01, -7.6376e-03,  ...,  3.6986e-01,\n",
       "            2.1574e-01,  5.6255e-01],\n",
       "          [-1.5771e-01, -7.5337e-02, -1.4065e-01,  ..., -3.8986e-02,\n",
       "            2.8103e-01,  1.0321e+00],\n",
       "          [ 2.3431e-01,  8.9713e-02,  2.4857e-01,  ..., -3.6024e-01,\n",
       "            1.2159e-01, -6.6376e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5598e-01,  1.0626e-01,  2.2022e-01,  ...,  5.2214e-01,\n",
       "           -8.1074e-02,  1.3789e-01],\n",
       "          [-1.8468e-01,  4.4324e-01,  3.9775e-01,  ..., -5.6378e-01,\n",
       "            2.4357e-02, -1.4211e-01],\n",
       "          [ 2.7656e-01, -6.8393e-02, -7.2752e-02,  ...,  1.7196e-01,\n",
       "            3.9732e-01,  1.8549e-01],\n",
       "          ...,\n",
       "          [ 2.2754e-01,  1.1399e-01,  6.6205e-02,  ..., -2.1901e-01,\n",
       "            1.9454e-01,  1.5027e-01],\n",
       "          [-1.9198e-01, -3.4131e-02, -1.2947e-01,  ..., -1.7822e-02,\n",
       "            2.0792e-01, -6.8057e-02],\n",
       "          [ 2.4169e-01,  1.6212e-01,  2.8259e-01,  ...,  5.5884e-01,\n",
       "            2.0451e-01,  3.3795e-01]],\n",
       "\n",
       "         [[ 1.9075e-01,  1.1022e-01,  2.4640e-01,  ...,  6.5970e-01,\n",
       "           -1.0029e-01,  4.6595e-02],\n",
       "          [-1.5671e-01,  4.4645e-01,  3.8520e-01,  ..., -7.4180e-01,\n",
       "            3.3805e-02, -1.4154e-01],\n",
       "          [ 2.6482e-01, -7.4631e-02, -5.3147e-02,  ...,  2.2422e-01,\n",
       "            3.9189e-01,  2.2363e-01],\n",
       "          ...,\n",
       "          [ 2.2254e-01,  9.9502e-02,  7.6407e-02,  ..., -2.5238e-01,\n",
       "            1.4895e-01,  6.7416e-02],\n",
       "          [-1.7975e-01, -4.0544e-02, -1.3445e-01,  ..., -2.6543e-02,\n",
       "            2.2458e-01, -9.2291e-02],\n",
       "          [ 3.3089e-01,  1.7207e-01,  2.2888e-01,  ...,  5.2610e-01,\n",
       "            2.0358e-01,  4.3935e-01]],\n",
       "\n",
       "         [[ 1.9913e-01,  1.0039e-01,  2.1117e-01,  ...,  4.9934e-01,\n",
       "           -8.9892e-02,  1.4243e-01],\n",
       "          [-1.2025e-01,  4.1492e-01,  3.9391e-01,  ..., -5.0305e-01,\n",
       "            4.3028e-02, -1.4802e-01],\n",
       "          [ 2.2172e-01, -6.6600e-02, -7.6105e-02,  ...,  1.7498e-01,\n",
       "            4.2727e-01,  2.2615e-01],\n",
       "          ...,\n",
       "          [ 3.7496e-01,  1.6010e-01,  1.3728e-01,  ..., -3.4772e-01,\n",
       "            1.3630e-01,  4.6792e-02],\n",
       "          [-1.5345e-01, -3.9906e-02, -1.3529e-01,  ..., -3.9288e-02,\n",
       "            2.1502e-01, -7.9424e-02],\n",
       "          [ 2.1108e-01,  1.4279e-01,  2.4631e-01,  ...,  5.7042e-01,\n",
       "            1.8782e-01,  3.8972e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9230e-01,  2.7991e-01,  1.5188e-01,  ...,  3.8475e-01,\n",
       "           -4.2857e-01,  3.7578e-01],\n",
       "          [-2.2879e-01,  7.7949e-01,  5.3871e-01,  ..., -4.0459e-01,\n",
       "           -9.4172e-02,  1.5429e-02],\n",
       "          [ 8.2717e-03, -1.3095e-01, -3.0307e-02,  ...,  3.3265e-01,\n",
       "            6.0288e-01,  1.1894e-02],\n",
       "          ...,\n",
       "          [ 2.1428e-01,  1.5022e-01,  6.1935e-02,  ..., -5.0569e-01,\n",
       "            1.6848e-01, -5.0991e-02],\n",
       "          [-1.7245e-01, -9.0090e-02, -2.0673e-01,  ..., -2.6206e-01,\n",
       "            4.5779e-01, -3.7651e-01],\n",
       "          [ 3.8243e-01,  1.9828e-01,  3.4725e-01,  ...,  9.6438e-01,\n",
       "            3.1750e-01,  1.0260e+00]],\n",
       "\n",
       "         [[ 1.7226e-01,  2.5527e-01,  1.2524e-01,  ...,  5.5819e-01,\n",
       "           -5.7360e-01,  3.8448e-01],\n",
       "          [-2.0269e-01,  7.7715e-01,  4.1304e-01,  ..., -4.2743e-01,\n",
       "           -1.2136e-01,  8.8289e-02],\n",
       "          [-1.6313e-02, -1.8102e-01, -5.4934e-02,  ...,  4.7432e-02,\n",
       "            7.8932e-01,  5.5193e-01],\n",
       "          ...,\n",
       "          [ 6.0101e-01,  2.0148e-01,  1.2393e-01,  ..., -5.4678e-01,\n",
       "            2.9165e-01, -6.7880e-02],\n",
       "          [-1.3434e-01, -4.8441e-02, -1.4511e-01,  ..., -1.7467e-01,\n",
       "            5.4928e-01, -2.7756e-01],\n",
       "          [ 2.7402e-01,  1.7796e-01,  3.0480e-01,  ...,  1.1791e+00,\n",
       "            2.7996e-01,  6.9197e-01]],\n",
       "\n",
       "         [[ 3.0301e-01,  2.7524e-01,  2.0970e-01,  ...,  2.0382e-01,\n",
       "           -4.0377e-01,  2.3367e-02],\n",
       "          [-3.0389e-02,  6.3539e-01,  3.5283e-01,  ..., -3.7370e-01,\n",
       "           -7.3418e-02, -3.1207e-02],\n",
       "          [ 1.6284e-02, -1.8782e-01, -5.6122e-02,  ..., -1.0256e-01,\n",
       "            4.6424e-01,  4.1709e-01],\n",
       "          ...,\n",
       "          [ 3.0844e-01,  1.5362e-01,  4.7767e-02,  ..., -2.5069e-01,\n",
       "            2.6544e-01,  6.4298e-02],\n",
       "          [-2.5577e-01, -6.4910e-02, -1.3127e-01,  ..., -1.9176e-02,\n",
       "            3.1721e-01, -7.0080e-02],\n",
       "          [ 2.4105e-01,  2.3994e-01,  3.2824e-01,  ...,  1.2470e+00,\n",
       "            3.6869e-01,  4.9576e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5598e-01,  1.0626e-01,  2.2022e-01,  ...,  5.2214e-01,\n",
       "           -8.1074e-02,  1.3789e-01],\n",
       "          [-1.8468e-01,  4.4324e-01,  3.9775e-01,  ..., -5.6378e-01,\n",
       "            2.4357e-02, -1.4211e-01],\n",
       "          [ 2.7656e-01, -6.8393e-02, -7.2752e-02,  ...,  1.7196e-01,\n",
       "            3.9732e-01,  1.8549e-01],\n",
       "          ...,\n",
       "          [ 2.2754e-01,  1.1399e-01,  6.6205e-02,  ..., -2.1901e-01,\n",
       "            1.9454e-01,  1.5027e-01],\n",
       "          [-1.9198e-01, -3.4131e-02, -1.2947e-01,  ..., -1.7822e-02,\n",
       "            2.0792e-01, -6.8057e-02],\n",
       "          [ 2.4169e-01,  1.6212e-01,  2.8259e-01,  ...,  5.5884e-01,\n",
       "            2.0451e-01,  3.3795e-01]],\n",
       "\n",
       "         [[ 2.8419e-01,  8.8769e-02,  2.3983e-01,  ...,  3.5792e-01,\n",
       "           -9.3946e-02,  5.6649e-02],\n",
       "          [-2.7403e-01,  4.8786e-01,  3.9293e-01,  ..., -4.4389e-01,\n",
       "            2.4956e-02, -6.9031e-03],\n",
       "          [ 3.0631e-01, -5.1254e-02, -7.0266e-02,  ...,  1.8790e-01,\n",
       "            4.1677e-01,  1.1470e-01],\n",
       "          ...,\n",
       "          [ 2.8023e-01,  1.1211e-01,  6.4210e-02,  ..., -7.4460e-02,\n",
       "            2.0794e-01,  1.0354e-01],\n",
       "          [-2.2874e-01, -3.2468e-02, -1.2251e-01,  ..., -2.9004e-02,\n",
       "            2.2269e-01, -5.6640e-02],\n",
       "          [ 2.1866e-01,  1.3288e-01,  2.7434e-01,  ...,  5.2982e-01,\n",
       "            1.8879e-01,  3.3994e-01]],\n",
       "\n",
       "         [[ 4.9769e-01,  7.6931e-02,  3.0374e-01,  ...,  6.6876e-01,\n",
       "           -4.7012e-02, -1.0401e-01],\n",
       "          [-9.5643e-01,  6.0875e-01,  3.7980e-01,  ..., -9.2026e-01,\n",
       "            3.4915e-02,  1.1193e-01],\n",
       "          [ 1.0752e+00, -9.0087e-02, -7.8475e-02,  ...,  3.0041e-01,\n",
       "            3.8584e-01,  2.5860e-01],\n",
       "          ...,\n",
       "          [ 2.2003e-01,  1.0332e-01,  5.3053e-02,  ..., -3.8804e-01,\n",
       "            1.3277e-01, -2.3730e-01],\n",
       "          [-7.6109e-01, -5.2657e-02, -1.1181e-01,  ..., -9.5720e-02,\n",
       "            1.9090e-01, -4.3867e-02],\n",
       "          [ 4.0723e-01,  1.6352e-01,  2.7677e-01,  ...,  3.3535e-01,\n",
       "            1.5709e-01,  3.8036e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6087e-01, -3.8554e-01,  1.0288e-01,  ...,  1.4500e+01,\n",
       "            1.1902e+00, -2.1675e+00],\n",
       "          [ 2.1404e-01, -2.2632e+00,  3.9157e-01,  ...,  4.6476e+00,\n",
       "            3.5725e-01,  1.3409e+00],\n",
       "          [-9.3217e-02,  1.8311e+00, -5.7230e-02,  ..., -3.0738e+00,\n",
       "            1.4224e-01, -1.7130e+00],\n",
       "          ...,\n",
       "          [ 4.3584e-01, -5.2846e-02,  4.0618e-02,  ...,  1.2094e+01,\n",
       "           -4.8829e-01,  1.5261e+00],\n",
       "          [ 3.1082e-01,  8.1329e-01, -1.7958e-01,  ...,  2.9238e+00,\n",
       "           -5.1146e-01, -1.3329e-01],\n",
       "          [-2.6113e-01, -2.1604e+00,  4.9310e-01,  ..., -1.4989e+01,\n",
       "            2.1369e-01,  2.6025e+00]],\n",
       "\n",
       "         [[-4.5851e-01, -6.4980e-02,  1.4587e-01,  ...,  6.3326e+00,\n",
       "            6.8953e-01, -4.4747e-01],\n",
       "          [ 3.5059e-01, -9.3759e-01,  3.8750e-01,  ...,  3.9830e+00,\n",
       "            1.1348e-01,  3.2311e-01],\n",
       "          [-3.8631e-01,  6.9016e-01, -8.8143e-02,  ..., -1.9281e+00,\n",
       "            1.5393e-01, -4.4326e-01],\n",
       "          ...,\n",
       "          [ 7.2284e-01,  4.5486e-01, -2.9924e-02,  ...,  6.8166e+00,\n",
       "           -3.9101e-01,  5.4389e-01],\n",
       "          [ 4.9634e-01,  4.0474e-01, -1.4913e-01,  ...,  1.3478e+00,\n",
       "            1.7600e-01, -2.4701e-02],\n",
       "          [-5.6478e-01, -8.6621e-01,  4.7233e-01,  ..., -8.2589e+00,\n",
       "            2.0924e-01,  6.3707e-01]],\n",
       "\n",
       "         [[-4.2467e-01, -8.2678e-02,  1.5289e-01,  ...,  1.4922e+00,\n",
       "            7.9553e-01, -5.6591e-01],\n",
       "          [ 3.5105e-01, -2.1099e+00,  4.3711e-01,  ...,  1.0207e+00,\n",
       "            1.8418e-01,  2.9392e-01],\n",
       "          [-9.1848e-01,  7.4224e-01, -1.6609e-01,  ..., -8.9158e-01,\n",
       "            1.4160e-02, -6.5658e-01],\n",
       "          ...,\n",
       "          [ 7.8411e-01,  1.2735e+00, -4.2758e-02,  ...,  1.6306e+00,\n",
       "           -5.8954e-01,  8.0152e-01],\n",
       "          [ 5.1758e-01,  4.4638e-01, -1.3062e-01,  ...,  1.1522e-01,\n",
       "            4.6447e-01,  1.8432e-01],\n",
       "          [-6.5861e-01, -1.5569e+00,  6.0800e-01,  ..., -1.3299e+00,\n",
       "           -2.5021e-01,  6.9217e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 2.5598e-01,  1.0626e-01,  2.2022e-01,  ...,  5.2214e-01,\n",
       "           -8.1074e-02,  1.3789e-01],\n",
       "          [-1.8468e-01,  4.4324e-01,  3.9775e-01,  ..., -5.6378e-01,\n",
       "            2.4357e-02, -1.4211e-01],\n",
       "          [ 2.7656e-01, -6.8393e-02, -7.2752e-02,  ...,  1.7196e-01,\n",
       "            3.9732e-01,  1.8549e-01],\n",
       "          ...,\n",
       "          [ 2.2754e-01,  1.1399e-01,  6.6205e-02,  ..., -2.1901e-01,\n",
       "            1.9454e-01,  1.5027e-01],\n",
       "          [-1.9198e-01, -3.4131e-02, -1.2947e-01,  ..., -1.7822e-02,\n",
       "            2.0792e-01, -6.8057e-02],\n",
       "          [ 2.4169e-01,  1.6212e-01,  2.8259e-01,  ...,  5.5884e-01,\n",
       "            2.0451e-01,  3.3795e-01]],\n",
       "\n",
       "         [[ 2.4608e-01,  1.2267e-01,  2.2044e-01,  ...,  3.4885e-01,\n",
       "           -1.9312e-01, -6.0063e-02],\n",
       "          [-1.2976e-01,  4.0916e-01,  4.0441e-01,  ..., -4.2080e-01,\n",
       "            7.4873e-02, -4.4165e-01],\n",
       "          [ 2.0928e-01, -1.0797e-01, -1.4179e-01,  ...,  1.4139e-01,\n",
       "            3.8909e-01,  2.1040e-01],\n",
       "          ...,\n",
       "          [ 2.4415e-01,  1.1263e-01,  6.5930e-02,  ..., -1.7942e-01,\n",
       "            1.6415e-01,  2.2080e-01],\n",
       "          [-2.0659e-01, -3.1336e-02, -1.4241e-01,  ..., -9.6425e-03,\n",
       "            2.0506e-01, -8.9080e-02],\n",
       "          [ 1.9671e-01,  1.6897e-01,  2.9810e-01,  ...,  6.0611e-01,\n",
       "            2.5072e-01,  4.8301e-01]],\n",
       "\n",
       "         [[ 2.2676e-01,  1.2302e-01,  2.2120e-01,  ...,  2.1010e-01,\n",
       "           -2.7516e-01, -4.4931e-01],\n",
       "          [-9.7076e-02,  4.4157e-01,  4.6530e-01,  ..., -3.0840e-01,\n",
       "            1.0290e-01, -1.1243e+00],\n",
       "          [ 1.5844e-01, -1.7898e-01, -2.3383e-01,  ...,  1.6773e-01,\n",
       "            4.5638e-01,  2.9765e-01],\n",
       "          ...,\n",
       "          [ 1.5760e-01,  1.3414e-01,  8.5924e-02,  ..., -1.4993e-01,\n",
       "            1.8537e-01,  4.3605e-01],\n",
       "          [-1.6134e-01, -4.0694e-02, -1.5715e-01,  ..., -9.5069e-03,\n",
       "            2.2038e-01, -2.0942e-01],\n",
       "          [ 1.4148e-01,  1.8846e-01,  3.5016e-01,  ...,  4.9177e-01,\n",
       "            2.7865e-01,  1.1747e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7289e-01, -2.5045e+00,  2.5646e-01,  ...,  3.8853e-05,\n",
       "           -3.9890e-02,  6.6401e-02],\n",
       "          [-2.4630e-01, -2.0032e+00,  4.4004e-01,  ..., -5.4934e-01,\n",
       "           -2.1993e-03,  2.5559e-01],\n",
       "          [-6.3581e-03,  1.5622e+00,  2.1419e-02,  ...,  1.7772e-01,\n",
       "           -4.1098e-01, -2.0480e-03],\n",
       "          ...,\n",
       "          [ 4.6510e-02, -1.1753e-01,  1.0543e-01,  ..., -1.5668e-01,\n",
       "            5.2989e-02, -4.7570e-01],\n",
       "          [-1.3057e-01, -9.0520e-02, -1.1729e-01,  ...,  3.7728e-02,\n",
       "           -1.6371e-01,  1.0098e-01],\n",
       "          [ 6.5090e-01, -1.7653e+00,  1.2869e-01,  ...,  1.3037e+00,\n",
       "            8.0734e-01, -9.4651e-01]],\n",
       "\n",
       "         [[ 1.9871e-01, -7.9253e-01,  2.2207e-01,  ...,  1.2151e-01,\n",
       "           -3.9324e-02, -1.7376e-01],\n",
       "          [-1.8226e-01, -7.2648e-01,  4.5265e-01,  ..., -1.3419e+00,\n",
       "            6.2236e-03,  4.9894e-01],\n",
       "          [ 1.8363e-02,  8.6136e-01, -1.3883e-02,  ...,  3.9381e-02,\n",
       "           -2.3480e-01, -5.9783e-01],\n",
       "          ...,\n",
       "          [ 2.5183e-01, -3.3561e-01,  1.6840e-01,  ..., -5.3818e-01,\n",
       "            1.1975e-01, -5.3604e-01],\n",
       "          [-5.3721e-02,  1.5177e-01, -9.8039e-02,  ...,  6.0604e-02,\n",
       "            2.3095e-02,  3.5061e-01],\n",
       "          [ 5.7079e-01, -5.1509e-01,  6.6948e-02,  ...,  3.5143e+00,\n",
       "            6.3560e-01, -1.2000e+00]],\n",
       "\n",
       "         [[-1.4778e+01, -5.8907e-01,  3.2313e-01,  ..., -4.7816e-02,\n",
       "           -8.4948e-02, -9.7231e-01],\n",
       "          [ 6.9887e+00, -1.0042e+00,  1.1491e+00,  ..., -5.7873e-01,\n",
       "            2.2450e-01, -5.9477e+00],\n",
       "          [ 1.3895e+00,  4.2819e-01,  9.9220e-02,  ...,  4.1566e-01,\n",
       "           -5.0493e-02,  4.3602e+00],\n",
       "          ...,\n",
       "          [-7.6897e+00, -1.5310e-01,  2.4665e-01,  ..., -2.9364e-01,\n",
       "            3.9327e-02,  1.5098e+00],\n",
       "          [ 7.6323e+00,  3.8701e-01, -4.0079e-02,  ..., -1.2772e-01,\n",
       "            5.2682e-02,  2.6447e-01],\n",
       "          [-1.5383e+01, -2.8673e-01, -3.8292e-01,  ...,  1.8764e+00,\n",
       "            2.5150e-01,  3.7426e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5598e-01,  1.0626e-01,  2.2022e-01,  ...,  5.2214e-01,\n",
       "           -8.1074e-02,  1.3789e-01],\n",
       "          [-1.8468e-01,  4.4324e-01,  3.9775e-01,  ..., -5.6378e-01,\n",
       "            2.4357e-02, -1.4211e-01],\n",
       "          [ 2.7656e-01, -6.8393e-02, -7.2752e-02,  ...,  1.7196e-01,\n",
       "            3.9732e-01,  1.8549e-01],\n",
       "          ...,\n",
       "          [ 2.2754e-01,  1.1399e-01,  6.6205e-02,  ..., -2.1901e-01,\n",
       "            1.9454e-01,  1.5027e-01],\n",
       "          [-1.9198e-01, -3.4131e-02, -1.2947e-01,  ..., -1.7822e-02,\n",
       "            2.0792e-01, -6.8057e-02],\n",
       "          [ 2.4169e-01,  1.6212e-01,  2.8259e-01,  ...,  5.5884e-01,\n",
       "            2.0451e-01,  3.3795e-01]],\n",
       "\n",
       "         [[ 4.6192e-01,  1.3436e-01,  2.3473e-01,  ...,  3.5237e-01,\n",
       "           -5.4912e-02,  1.8813e-01],\n",
       "          [-2.9207e-01,  4.7955e-01,  4.5196e-01,  ..., -3.3959e-01,\n",
       "            4.3000e-02, -1.2070e-01],\n",
       "          [-6.2425e-02, -5.2099e-02, -2.0800e-01,  ...,  1.7180e-01,\n",
       "            3.1009e-01,  4.5178e-01],\n",
       "          ...,\n",
       "          [ 3.3129e-01,  8.2617e-02,  8.1260e-02,  ..., -1.1697e-01,\n",
       "            1.8685e-01,  1.0205e-01],\n",
       "          [-2.9600e-01, -3.6812e-02, -1.4183e-01,  ..., -1.1643e-02,\n",
       "            2.5482e-01, -5.6730e-02],\n",
       "          [ 3.1062e-01,  1.1828e-01,  3.5235e-01,  ...,  6.1731e-01,\n",
       "            1.7775e-01,  1.4106e-01]],\n",
       "\n",
       "         [[ 1.5399e-01,  1.3835e-01,  2.2272e-01,  ...,  5.0943e-01,\n",
       "           -3.2451e-02,  1.8830e-01],\n",
       "          [-2.4483e-01,  5.1873e-01,  4.9585e-01,  ..., -7.9924e-01,\n",
       "            5.2727e-02, -1.0419e-01],\n",
       "          [ 3.3847e-01, -1.7159e-01, -2.4044e-01,  ...,  3.1818e-01,\n",
       "            3.1895e-01,  3.7423e-01],\n",
       "          ...,\n",
       "          [ 2.2262e-01,  7.4497e-02,  6.0437e-02,  ..., -3.7382e-01,\n",
       "            9.6826e-02,  9.9605e-02],\n",
       "          [-2.2768e-01, -4.3738e-02, -1.4831e-01,  ..., -2.1798e-02,\n",
       "            2.5602e-01, -6.6834e-02],\n",
       "          [ 3.1060e-01,  1.4192e-01,  3.5271e-01,  ...,  6.1882e-01,\n",
       "            2.3322e-01,  1.3703e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5983e-01,  1.6992e-01,  5.5849e-02,  ...,  3.5274e-01,\n",
       "           -6.6372e-02,  7.6869e-01],\n",
       "          [-7.6077e-01,  4.6575e-01,  5.2008e-01,  ..., -8.9007e-01,\n",
       "           -4.6884e-01, -1.9912e-01],\n",
       "          [ 3.1030e-01, -2.0313e-01, -1.0124e-02,  ...,  2.0579e-01,\n",
       "            6.2563e-01,  2.0153e-01],\n",
       "          ...,\n",
       "          [ 3.0337e-01,  2.3444e-01,  6.3487e-02,  ..., -1.4794e-01,\n",
       "            3.7692e-01, -4.2787e-01],\n",
       "          [-4.0781e-01, -8.5806e-02, -1.2746e-01,  ..., -3.7789e-02,\n",
       "            4.7128e-01, -1.4280e-01],\n",
       "          [ 4.0074e-01,  1.3939e-01,  2.1646e-01,  ...,  6.6959e-01,\n",
       "            4.4117e-01,  1.8311e-01]],\n",
       "\n",
       "         [[ 1.2157e+01,  2.2300e-01,  1.0616e-01,  ...,  1.5847e+00,\n",
       "           -1.6454e-01,  7.1669e-01],\n",
       "          [-3.9490e+01,  4.6879e-01,  4.6788e-01,  ..., -4.4848e+00,\n",
       "           -6.1115e-01, -1.5262e-01],\n",
       "          [-3.3456e+01, -2.1899e-01,  2.3416e-01,  ...,  3.3391e+00,\n",
       "            9.8973e-01, -2.7320e-01],\n",
       "          ...,\n",
       "          [ 2.0401e+01,  2.2292e-01,  4.2139e-02,  ..., -2.8194e-01,\n",
       "            6.5481e-01, -2.1475e-03],\n",
       "          [-2.2294e+01, -8.7474e-02, -8.8172e-02,  ..., -2.0394e-01,\n",
       "            8.6190e-01, -1.0036e-01],\n",
       "          [ 2.5875e+01,  1.5937e-01,  4.6358e-02,  ..., -2.2760e+00,\n",
       "           -6.9571e-02,  2.9887e-01]],\n",
       "\n",
       "         [[ 6.4478e-01,  9.8632e-02, -1.2419e-02,  ...,  9.0894e-01,\n",
       "           -2.9969e-01,  4.4702e-01],\n",
       "          [-1.0138e+00,  4.9644e-01,  4.4807e-01,  ...,  7.5801e+00,\n",
       "           -1.9918e-01, -9.2802e-02],\n",
       "          [-1.0969e+00, -1.6431e-01,  2.4776e-01,  ..., -6.7097e+00,\n",
       "            7.4894e-01, -2.2018e-01],\n",
       "          ...,\n",
       "          [ 7.4669e-01,  1.9251e-01,  6.0079e-02,  ...,  8.3615e-01,\n",
       "            5.0370e-01, -3.6387e-02],\n",
       "          [-6.3685e-01, -4.6219e-02, -1.1873e-01,  ...,  2.2048e-01,\n",
       "            5.0206e-01, -1.1298e-01],\n",
       "          [ 7.2817e-01,  1.8391e-01,  1.1960e-01,  ...,  3.5992e+00,\n",
       "            2.3230e-02,  4.1788e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5598e-01,  1.0626e-01,  2.2022e-01,  ...,  5.2214e-01,\n",
       "           -8.1074e-02,  1.3789e-01],\n",
       "          [-1.8468e-01,  4.4324e-01,  3.9775e-01,  ..., -5.6378e-01,\n",
       "            2.4357e-02, -1.4211e-01],\n",
       "          [ 2.7656e-01, -6.8393e-02, -7.2752e-02,  ...,  1.7196e-01,\n",
       "            3.9732e-01,  1.8549e-01],\n",
       "          ...,\n",
       "          [ 2.2754e-01,  1.1399e-01,  6.6205e-02,  ..., -2.1901e-01,\n",
       "            1.9454e-01,  1.5027e-01],\n",
       "          [-1.9198e-01, -3.4131e-02, -1.2947e-01,  ..., -1.7822e-02,\n",
       "            2.0792e-01, -6.8057e-02],\n",
       "          [ 2.4169e-01,  1.6212e-01,  2.8259e-01,  ...,  5.5884e-01,\n",
       "            2.0451e-01,  3.3795e-01]],\n",
       "\n",
       "         [[ 7.7627e-02,  4.2971e-02,  2.0732e-01,  ...,  5.2506e-01,\n",
       "           -5.1299e-02,  1.3195e-01],\n",
       "          [-1.7852e-01,  4.9188e-01,  4.1270e-01,  ..., -4.3673e-01,\n",
       "            1.4578e-01, -6.7428e-02],\n",
       "          [ 3.4908e-01, -1.0295e-01, -8.2280e-02,  ...,  6.6643e-02,\n",
       "            3.3785e-01,  2.0290e-01],\n",
       "          ...,\n",
       "          [ 2.7322e-01,  1.4509e-01,  6.6404e-02,  ..., -2.3000e-01,\n",
       "            1.4901e-01,  1.1174e-01],\n",
       "          [-2.4015e-01, -4.9637e-02, -1.2817e-01,  ..., -2.4753e-02,\n",
       "            1.9258e-01, -4.5749e-02],\n",
       "          [ 2.9341e-01,  1.7983e-01,  3.0865e-01,  ...,  4.8004e-01,\n",
       "            1.8402e-01,  3.2586e-01]],\n",
       "\n",
       "         [[ 1.9848e-01,  8.4092e-02,  1.7905e-01,  ...,  6.5203e-01,\n",
       "           -8.2984e-02, -5.4567e-02],\n",
       "          [-1.5699e-01,  5.0009e-01,  3.6865e-01,  ..., -8.3396e-01,\n",
       "            1.2569e-01, -1.5024e-01],\n",
       "          [ 3.3270e-01, -9.3137e-02, -7.5294e-02,  ...,  2.1948e-01,\n",
       "            3.3962e-01,  2.4063e-01],\n",
       "          ...,\n",
       "          [ 2.0288e-01,  1.3479e-01,  6.5677e-02,  ..., -2.5722e-01,\n",
       "            1.5439e-01,  1.4990e-01],\n",
       "          [-1.9647e-01, -4.5318e-02, -1.2627e-01,  ..., -3.8609e-02,\n",
       "            2.1328e-01, -7.4438e-02],\n",
       "          [ 2.4318e-01,  1.7480e-01,  3.2075e-01,  ...,  4.9074e-01,\n",
       "            2.0337e-01,  4.2419e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3655e+00,  3.5863e-01,  1.5047e-01,  ...,  8.9599e-01,\n",
       "           -1.7747e-01,  2.9052e-01],\n",
       "          [ 6.1102e-01,  1.2482e+00,  9.5412e-01,  ..., -1.2299e+00,\n",
       "            1.3298e+00,  2.4668e-01],\n",
       "          [-2.2692e-01, -2.9151e-01, -4.4947e-01,  ...,  1.2226e+00,\n",
       "            3.9262e+00, -1.9105e-01],\n",
       "          ...,\n",
       "          [ 5.9296e-01, -8.6652e-01, -7.2402e-02,  ..., -8.8738e-01,\n",
       "           -6.2361e+00,  7.2578e-01],\n",
       "          [ 1.0477e+00, -2.2431e-01, -3.2741e-01,  ..., -1.1767e-01,\n",
       "            2.1795e+00,  1.3047e-01],\n",
       "          [-1.5380e-01,  5.4415e-01,  2.6065e-01,  ...,  8.0537e-01,\n",
       "            1.7321e+00, -1.9596e-01]],\n",
       "\n",
       "         [[ 4.2536e+00,  5.2518e-01,  1.8579e-01,  ...,  9.2483e-01,\n",
       "           -5.9548e-01,  2.5591e-01],\n",
       "          [-2.2280e+00,  1.8118e+00,  1.1971e+00,  ..., -1.1867e+00,\n",
       "            2.0299e+00,  2.1428e-01],\n",
       "          [ 1.3739e+00, -4.0202e-01, -6.7267e-01,  ...,  9.1375e-01,\n",
       "            5.9716e+00, -2.0014e-01],\n",
       "          ...,\n",
       "          [-1.3250e-01, -1.5610e+00, -2.3585e-01,  ..., -1.7421e-01,\n",
       "           -1.0544e+01,  7.9904e-01],\n",
       "          [-3.0987e+00, -2.4069e-01, -3.9264e-01,  ..., -6.0567e-02,\n",
       "            3.0031e+00,  4.5525e-02],\n",
       "          [ 7.1306e-01,  7.2889e-01,  2.5693e-01,  ...,  5.6763e-01,\n",
       "            2.2819e+00, -1.6453e-01]],\n",
       "\n",
       "         [[ 1.3301e+00,  4.8205e-01,  7.4732e-02,  ...,  3.7498e-01,\n",
       "           -1.0733e-01,  5.6430e-01],\n",
       "          [ 1.7336e-02,  7.1071e-01,  5.4148e-01,  ..., -4.3949e-01,\n",
       "            1.2461e-01,  4.4285e-01],\n",
       "          [-3.2477e-01, -2.4382e-01,  2.8427e-02,  ...,  7.8737e-01,\n",
       "            6.6358e-01, -1.1499e-01],\n",
       "          ...,\n",
       "          [-1.9783e-01, -3.8914e-02,  2.5977e-02,  ...,  2.6824e-02,\n",
       "           -2.5576e-01,  3.8423e-01],\n",
       "          [-9.6346e-01, -1.5488e-01, -2.5565e-01,  ..., -4.0632e-02,\n",
       "            3.9626e-01,  2.7458e-02],\n",
       "          [ 2.9162e-01,  5.0673e-01,  3.4265e-01,  ...,  3.3194e-01,\n",
       "            3.5608e-01, -3.6525e-01]]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions_all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 64, 16384])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.1.attn.hook_z'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg[\"act_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HookedRootModule.hook_points of HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x TransformerBlock(\n",
       "      (ln1): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hook_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Connor's SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auto_encoder_runs = [\n",
    "    \"gpt2-small_L0_Hcat_z_lr1.20e-03_l11.80e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L1_Hcat_z_lr1.20e-03_l18.00e-01_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v5\",\n",
    "    \"gpt2-small_L2_Hcat_z_lr1.20e-03_l11.00e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v4\",\n",
    "    \"gpt2-small_L3_Hcat_z_lr1.20e-03_l19.00e-01_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L4_Hcat_z_lr1.20e-03_l11.10e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v7\",\n",
    "    \"gpt2-small_L5_Hcat_z_lr1.20e-03_l11.00e+00_ds49152_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L6_Hcat_z_lr1.20e-03_l11.10e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L7_Hcat_z_lr1.20e-03_l11.10e+00_ds49152_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L8_Hcat_z_lr1.20e-03_l11.30e+00_ds24576_bs4096_dc1.00e-05_rsanthropic_rie25000_nr4_v6\",\n",
    "    \"gpt2-small_L9_Hcat_z_lr1.20e-03_l11.20e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L10_Hcat_z_lr1.20e-03_l11.30e+00_ds24576_bs4096_dc1.00e-05_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L11_Hcat_z_lr1.20e-03_l13.00e+00_ds24576_bs4096_dc3.16e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "][:2]\n",
    "\n",
    "hf_repo = \"ckkissane/attn-saes-gpt2-small-all-layers\"\n",
    "\n",
    "gpt2_sae = {}\n",
    "for auto_encoder_run in auto_encoder_runs:\n",
    "    attn_sae_cfg = download_file_from_hf(hf_repo, f\"{auto_encoder_run}_cfg.json\")\n",
    "    cfg = utils.AttnToHookedCfg(attn_sae_cfg)\n",
    "\n",
    "    state_dict = download_file_from_hf(hf_repo, f\"{auto_encoder_run}.pt\", force_is_torch=True)\n",
    "\n",
    "    hooked_sae = HookedSAE(cfg)\n",
    "    hooked_sae.load_state_dict(state_dict)\n",
    "\n",
    "    gpt2_sae[cfg.hook_name] = hooked_sae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auto_encoder_runs = [\n",
    "    \"gpt2-small_L0_Hcat_z_lr1.20e-03_l11.80e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L1_Hcat_z_lr1.20e-03_l18.00e-01_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v5\",\n",
    "    \"gpt2-small_L2_Hcat_z_lr1.20e-03_l11.00e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v4\",\n",
    "    \"gpt2-small_L3_Hcat_z_lr1.20e-03_l19.00e-01_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L4_Hcat_z_lr1.20e-03_l11.10e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v7\",\n",
    "    \"gpt2-small_L5_Hcat_z_lr1.20e-03_l11.00e+00_ds49152_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L6_Hcat_z_lr1.20e-03_l11.10e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L7_Hcat_z_lr1.20e-03_l11.10e+00_ds49152_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L8_Hcat_z_lr1.20e-03_l11.30e+00_ds24576_bs4096_dc1.00e-05_rsanthropic_rie25000_nr4_v6\",\n",
    "    \"gpt2-small_L9_Hcat_z_lr1.20e-03_l11.20e+00_ds24576_bs4096_dc1.00e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L10_Hcat_z_lr1.20e-03_l11.30e+00_ds24576_bs4096_dc1.00e-05_rsanthropic_rie25000_nr4_v9\",\n",
    "    \"gpt2-small_L11_Hcat_z_lr1.20e-03_l13.00e+00_ds24576_bs4096_dc3.16e-06_rsanthropic_rie25000_nr4_v9\",\n",
    "][:2]\n",
    "\n",
    "hf_repo = \"ckkissane/attn-saes-gpt2-small-all-layers\"\n",
    "\n",
    "gpt2_sae = {}\n",
    "for auto_encoder_run in auto_encoder_runs:\n",
    "    attn_sae_cfg = download_file_from_hf(hf_repo, f\"{auto_encoder_run}_cfg.json\")\n",
    "    cfg = utils.AttnToHookedCfg(attn_sae_cfg)\n",
    "\n",
    "    state_dict = download_file_from_hf(hf_repo, f\"{auto_encoder_run}.pt\", force_is_torch=True)\n",
    "\n",
    "    hooked_sae = HookedSAE(cfg)\n",
    "    hooked_sae.load_state_dict(state_dict)\n",
    "\n",
    "    gpt2_sae[cfg.hook_name] = hooked_sae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_connor_rob_sae_to_our_saelens_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for HookedSAE:\n\tMissing key(s) in state_dict: \"cfg.b_enc\", \"cfg.W_dec\", \"cfg.W_enc\", \"cfg.b_dec\", \"cfg.scaling_factor\". \n\tUnexpected key(s) in state_dict: \"scaling_factor\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10867/3236798432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_connor_rob_sae_to_our_saelens_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mhooked_sae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHookedSAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhooked_sae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for HookedSAE:\n\tMissing key(s) in state_dict: \"cfg.b_enc\", \"cfg.W_dec\", \"cfg.W_enc\", \"cfg.b_dec\", \"cfg.scaling_factor\". \n\tUnexpected key(s) in state_dict: \"scaling_factor\". "
     ]
    }
   ],
   "source": [
    "cfg = utils.download_file_from_hf(\"ckkissane/tinystories-1M-SAES\", f\"concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78_cfg.json\")\n",
    "state_dict = utils.download_file_from_hf(\n",
    "    \"ckkissane/tinystories-1M-SAES\", \n",
    "    f\"concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78.pt\", force_is_torch=True)\n",
    "\n",
    "# Scaling factor isn't in there...\n",
    "state_dict['scaling_factor'] = t.zeros(16384) + 1.0\n",
    "cfg = convert_connor_rob_sae_to_our_saelens_format(state_dict, cfg)\n",
    "hooked_sae = HookedSAE(cfg)\n",
    "hooked_sae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (activation_fn): ReLU()\n",
       "  (hook_sae_in): HookPoint()\n",
       "  (hook_hidden_pre): HookPoint()\n",
       "  (hook_hidden_post): HookPoint()\n",
       "  (hook_sae_out): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W_enc',\n",
       "              tensor([[ 0.2044, -0.0199,  0.0279,  ...,  0.0148, -0.1189, -0.0596],\n",
       "                      [ 0.3211,  0.1868, -0.1152,  ..., -0.0468, -0.0330,  0.0839],\n",
       "                      [-0.1102,  0.0113, -0.2738,  ..., -0.0475,  0.2933,  0.0236],\n",
       "                      ...,\n",
       "                      [ 0.1117, -0.0707, -0.0317,  ..., -0.1070,  0.0881, -0.0343],\n",
       "                      [ 0.2446, -0.0421, -0.3265,  ...,  0.2763,  0.3841, -0.0037],\n",
       "                      [ 0.2897,  0.0543,  0.1597,  ..., -0.1054, -0.0634,  0.0200]])),\n",
       "             ('W_dec',\n",
       "              tensor([[ 3.7850e-02,  1.5909e-02,  6.2841e-02,  ...,  3.6816e-02,\n",
       "                        7.6473e-02,  2.6904e-02],\n",
       "                      [-2.7682e-02,  4.9892e-02, -1.8354e-02,  ..., -2.5450e-02,\n",
       "                        3.8812e-02,  1.5600e-02],\n",
       "                      [-3.2753e-02, -6.8971e-03, -6.3753e-02,  ..., -5.1496e-02,\n",
       "                       -6.2393e-02,  5.6357e-02],\n",
       "                      ...,\n",
       "                      [-4.8899e-02, -2.4470e-02,  9.0868e-03,  ..., -6.3808e-02,\n",
       "                        3.2733e-01, -6.0334e-02],\n",
       "                      [ 1.9097e-04, -1.3462e-02, -1.0087e-02,  ..., -7.9443e-04,\n",
       "                       -4.2982e-03,  6.9143e-04],\n",
       "                      [ 7.2475e-02, -6.1008e-02,  2.2043e-02,  ..., -3.5905e-02,\n",
       "                        2.4664e-02, -5.9496e-02]])),\n",
       "             ('b_enc',\n",
       "              tensor([-6.0150, -4.3255, -5.3510,  ..., -1.7084, -3.3299, -2.0004])),\n",
       "             ('b_dec',\n",
       "              tensor([ 2.9475e-01,  4.3998e-01, -6.3292e-01, -4.8324e-02, -1.3911e-01,\n",
       "                       4.1454e-01, -9.2677e-02,  2.8746e-01,  1.4192e-01, -3.8640e-01,\n",
       "                      -1.8876e-01, -1.9363e-01,  2.5886e-01,  3.1635e-01,  3.0164e-01,\n",
       "                      -1.0904e-01, -2.1674e-01, -3.1289e-02,  3.1714e-01,  2.9907e-01,\n",
       "                      -1.8555e-01, -2.4097e-01, -1.4336e-01, -3.5192e-01,  5.8457e-02,\n",
       "                       7.9334e-01,  1.0346e-01, -1.1331e-01,  9.1581e-02, -3.8290e-01,\n",
       "                       1.2952e-01,  5.2771e-03, -2.8817e-01,  7.9212e-02, -1.0821e-01,\n",
       "                       1.2214e-01, -1.0368e-01, -2.3639e-01,  3.3960e-02,  8.6037e-02,\n",
       "                      -3.0832e-01, -4.3953e-01,  1.3017e-01,  1.8704e-01, -5.3036e-02,\n",
       "                       2.0282e-01,  8.3266e-03,  3.7137e-01,  4.8790e-01,  3.0437e-01,\n",
       "                      -5.4991e-02,  1.4188e-01, -6.0886e-01,  5.6002e-01,  3.6623e-01,\n",
       "                      -2.3382e-01,  1.4166e-01,  2.3899e-01, -4.4904e-01,  2.2261e-01,\n",
       "                      -2.2606e-01, -1.8635e-01,  6.0129e-02, -3.6031e-01,  3.9775e-02,\n",
       "                      -4.5243e-02,  2.3978e-01,  3.6054e-01, -1.6353e-01, -8.1514e-01,\n",
       "                       2.3013e-01,  4.8699e-01,  3.8609e-01,  7.0021e-02,  2.8686e-01,\n",
       "                       7.0540e-01,  4.0490e-01, -7.7019e-02, -2.7827e-01,  2.4031e-01,\n",
       "                      -5.3879e-02,  1.8116e-01, -3.1896e-01,  3.1176e-01,  6.3371e-01,\n",
       "                      -2.5748e-01,  1.2694e-01,  7.2285e-02,  4.0107e-01, -9.9735e-02,\n",
       "                      -2.1439e-01,  1.2995e-01,  4.9055e-01, -2.4368e-01, -2.3948e-02,\n",
       "                       9.3517e-01,  5.9982e-01,  1.1603e-02,  1.0849e-01,  3.3062e-01,\n",
       "                       1.1858e-01, -2.9250e-02,  1.5679e-02, -4.2077e-01,  1.1761e+00,\n",
       "                       5.3495e-01,  3.7823e-02, -1.5862e-01, -1.9310e-01, -1.0072e+00,\n",
       "                       6.1855e-01, -6.1457e-02,  1.6161e-01, -8.0207e-02, -4.7201e-01,\n",
       "                      -5.5316e-02,  4.6116e-01,  3.9831e-01, -6.5872e-01, -7.6528e-02,\n",
       "                       3.3248e-02,  3.1819e-02, -2.1141e-01,  2.6039e-01,  1.7241e-01,\n",
       "                      -4.1060e-01,  2.0729e-01,  4.6139e-01,  1.6979e-02, -2.1269e-01,\n",
       "                       1.3250e-01, -4.0630e-01, -5.2156e-01,  1.6588e-01, -2.7566e-01,\n",
       "                       3.2647e-01, -3.3785e-01, -3.8454e-01,  1.6424e-02,  3.2765e-01,\n",
       "                       5.9297e-02, -3.4703e-01,  4.8032e-02,  2.2887e-01, -8.9471e-02,\n",
       "                       1.9115e-01, -1.3278e-01, -1.0202e-01,  6.0975e-01, -1.3317e-01,\n",
       "                       8.3574e-02, -9.9688e-02,  3.2798e-01, -1.9881e-01,  2.7907e-01,\n",
       "                       2.3909e-01, -2.4756e-01,  3.5423e-01,  1.4393e-01,  1.8925e-01,\n",
       "                      -1.6145e-01, -4.2633e-01,  3.6148e-01,  1.8836e-01, -6.9628e-01,\n",
       "                      -6.5044e-01, -8.3979e-02, -3.4731e-01,  4.8295e-01, -1.2426e-01,\n",
       "                      -7.4651e-02, -6.5530e-02,  7.9232e-02, -1.1449e-01,  2.6874e-01,\n",
       "                       7.5311e-01, -4.8310e-01, -3.5463e-01, -3.4796e-01, -3.0081e-01,\n",
       "                      -3.2870e-01, -2.6786e-01, -4.9048e-01, -6.0963e-01,  4.1460e-01,\n",
       "                      -4.5408e-02, -5.0259e-01, -6.5589e-02,  2.6524e-01, -3.0397e-01,\n",
       "                       1.6461e-01,  2.2794e-01,  2.3491e-01,  2.8287e-01, -1.8984e-01,\n",
       "                       2.8794e-01,  1.1415e-01, -2.0646e-01,  9.5015e-02,  2.8584e-01,\n",
       "                       2.7506e-01,  1.2924e-01,  4.4332e-01,  3.5063e-01,  5.5960e-02,\n",
       "                       8.3192e-02,  2.0520e-01,  7.9206e-02, -2.4744e-01,  1.6296e-01,\n",
       "                      -1.3878e-01,  4.6864e-01, -5.1968e-02, -1.4836e-01,  3.7613e-02,\n",
       "                      -1.3859e-02, -6.5073e-02, -5.3297e-01, -4.1821e-01,  9.1152e-02,\n",
       "                       1.0548e-02,  3.0774e-01,  1.8965e-01, -4.0314e-01,  7.9080e-02,\n",
       "                       7.8198e-01, -4.4115e-01, -3.8602e-01,  9.9343e-02,  1.9913e-01,\n",
       "                      -9.6721e-02, -2.7199e-01, -5.1986e-01,  3.5472e-01,  3.5698e-01,\n",
       "                       4.2954e-01,  4.0457e-01,  1.5997e-01,  2.5885e-01, -6.8419e-02,\n",
       "                       5.3749e-01,  8.5408e-02, -3.9369e-01, -2.0222e-01, -6.5532e-03,\n",
       "                      -2.2771e-01, -7.5003e-02, -5.4506e-01,  5.3519e-02,  5.6025e-02,\n",
       "                      -4.4034e-01, -5.1548e-01, -1.8773e-01, -4.0504e-01,  1.0614e-02,\n",
       "                       2.2071e-01, -3.0615e-01,  4.1098e-01, -2.0795e-01, -9.6503e-02,\n",
       "                      -6.9599e-01, -1.1494e-03,  1.0043e-01,  4.1789e-01,  2.1497e-01,\n",
       "                      -9.3256e-02,  3.0881e-01, -3.3189e-01, -2.0080e-01, -7.2304e-02,\n",
       "                       2.1119e-02, -2.3015e-01, -2.1956e-01, -7.9414e-01, -3.1701e-01,\n",
       "                       9.3802e-02, -5.3629e-01,  1.3069e-01, -3.5648e-01,  1.9806e-01,\n",
       "                      -4.3100e-01, -3.0339e-01,  8.7380e-02, -7.8571e-01,  9.8904e-01,\n",
       "                      -1.2345e-01, -1.0401e-02, -3.4553e-01, -5.5954e-01,  1.8835e-01,\n",
       "                       2.2674e-01,  2.7617e-02, -6.4769e-02,  2.2709e-01, -2.1101e-02,\n",
       "                      -2.2638e-01,  3.9078e-01,  3.0382e-01, -6.7358e-02,  3.9219e-01,\n",
       "                       3.0494e-01,  1.1042e-01,  2.6763e-01, -1.4677e-01, -3.0119e-02,\n",
       "                      -2.2323e-01, -2.7485e-01, -1.2057e-01,  1.0730e-01,  1.4948e-01,\n",
       "                      -5.5858e-01,  1.9673e-02, -3.1785e-01,  3.7014e-02, -1.7230e-01,\n",
       "                       1.4077e-01,  8.3375e-02,  2.1714e-01,  1.4268e-01,  5.8456e-02,\n",
       "                      -1.2612e-01,  3.8114e-02, -4.3159e-01, -6.5984e-03, -2.4510e-01,\n",
       "                       1.6078e-01,  2.4844e-01,  4.1847e-02, -1.1101e-01,  5.4229e-02,\n",
       "                      -6.4670e-03, -1.8401e-01, -2.9318e-01,  5.7873e-02, -3.7964e-02,\n",
       "                       7.3478e-02,  1.0967e-01,  1.5992e-01,  2.2167e-01,  9.2443e-02,\n",
       "                      -1.7761e-02,  2.3935e-01, -6.7947e-02,  2.2110e-01,  9.2986e-02,\n",
       "                       1.2250e-01,  3.6119e-02, -9.6263e-02,  3.2661e-01,  2.3932e-02,\n",
       "                       2.4701e-01,  1.1336e-01, -3.0190e-01, -1.4386e-01,  1.7559e-01,\n",
       "                       2.6827e-01, -1.7410e-02,  2.5120e-01,  7.0272e-03,  1.0052e-02,\n",
       "                      -1.6398e-01, -3.6441e-01,  1.1736e+00,  2.6235e-01, -3.3751e-01,\n",
       "                      -1.6844e-01,  2.0276e-01, -1.2308e-01, -5.7073e-02, -6.0870e-03,\n",
       "                      -1.8238e-01, -1.1789e-01,  1.3617e-01,  2.4380e-01,  6.2796e-02,\n",
       "                      -8.6934e-04, -1.1153e-01, -3.5367e-01,  2.1279e-01, -3.0681e-02,\n",
       "                      -2.9319e-01, -1.9439e-02, -1.3579e-01,  1.9568e-02, -1.5682e-01,\n",
       "                       2.4051e-01,  3.1989e-01,  2.4211e-01,  5.1832e-01, -1.7241e-01,\n",
       "                       2.6599e-01, -2.8173e-01, -4.2175e-02, -1.0159e-01,  1.3251e-01,\n",
       "                      -1.2709e-01,  4.2281e-01,  3.3646e-01,  4.9610e-01,  6.1637e-02,\n",
       "                       2.9226e-01,  2.7950e-04, -1.8826e-01, -8.5839e-02, -1.9689e-01,\n",
       "                       1.9913e-01,  1.6044e-01,  1.8232e-01, -9.5096e-02,  1.9048e-01,\n",
       "                       5.2331e-03, -2.2706e-01, -2.6953e-01, -4.7139e-02, -1.5587e-01,\n",
       "                       1.7449e-01, -1.7095e-01,  2.0730e-01,  3.3417e-01, -7.1994e-02,\n",
       "                      -2.7121e-01, -1.1719e-01,  1.4473e-01, -1.5510e-01, -9.8123e-02,\n",
       "                      -5.2040e-01, -3.4525e-01, -1.7865e-02, -3.9929e-01,  1.8869e-01,\n",
       "                       2.3390e-01,  9.8094e-02, -1.5361e-01,  3.4351e-02, -1.0890e-01,\n",
       "                       8.6289e-02, -3.4310e-01,  3.9160e-01, -2.6007e-01,  4.9358e-02,\n",
       "                      -8.1195e-02, -1.6848e-01,  3.1032e-01,  2.3889e-01, -4.6421e-02,\n",
       "                      -3.6554e-02, -1.2202e-01,  3.5633e-01, -1.8690e-01, -4.2133e-02,\n",
       "                       4.0843e-01,  1.4050e-01,  8.7525e-02, -1.5966e-01,  2.2362e-01,\n",
       "                       4.7545e-01, -1.6467e-01, -1.9449e-02, -2.1445e-01, -1.1083e-01,\n",
       "                       3.1547e-01,  2.8572e-03, -7.3811e-02, -9.9294e-02, -3.1108e-01,\n",
       "                      -7.7140e-02, -1.9436e-02, -3.7492e-01, -1.0701e-01,  3.8888e-01,\n",
       "                       1.7644e-01, -2.9748e-01,  1.4703e-01, -1.3503e-01, -8.2773e-02,\n",
       "                      -3.2295e-01, -4.2516e-01,  1.5103e-01, -5.5121e-02, -1.3091e-01,\n",
       "                      -2.4309e-01,  3.2830e-01,  4.1301e-01,  2.6350e-02, -5.6407e-02,\n",
       "                      -4.7107e-02, -3.8476e-02,  5.3189e-01, -4.5338e-02,  6.7695e-03,\n",
       "                       2.2510e-01, -1.2433e-01,  1.1702e-01, -3.8516e-01, -4.6056e-02,\n",
       "                       1.2795e-02,  1.0926e-01, -8.0553e-02, -2.3377e-01,  2.6943e-01,\n",
       "                       4.0049e-01,  1.0033e-01, -2.7906e-01,  2.5254e-01,  1.5239e-01,\n",
       "                      -6.1315e-01,  4.7106e-01,  9.7470e-02, -2.2808e-02,  2.8031e-01,\n",
       "                       3.5855e-02,  3.4515e-03])),\n",
       "             ('scaling_factor', tensor([1., 1., 1.,  ..., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'scaling_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10867/4160962898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scaling_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'scaling_factor'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['seed', 'batch_size', 'buffer_mult', 'lr', 'num_tokens', 'l1_coeff', 'beta1', 'beta2', 'dict_mult', 'seq_len', 'enc_dtype', 'model_name', 'site', 'layer', 'device', 'reinit', 'head', 'concat_heads', 'dead_direction_cutoff', 're_init_every', 'anthropic_resample_last', 'resample_factor', 'num_resamples', 'wandb_project_name', 'wandb_entity', 'save_state_dict_every', 'model_batch_size', 'buffer_size', 'buffer_batches', 'act_name', 'act_size', 'dict_size', 'name'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10867/91669102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'state_dict'"
     ]
    }
   ],
   "source": [
    "state_dict['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/.cache/huggingface/hub/models--ckkissane--tinystories-1M-SAES/snapshots/d801037ff55db27e9c1e9d11c9003e51fbfc52aa/./concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78.pt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 49,\n",
       " 'batch_size': 4096,\n",
       " 'buffer_mult': 384,\n",
       " 'lr': 0.001,\n",
       " 'num_tokens': 2000000000,\n",
       " 'l1_coeff': 2.0,\n",
       " 'beta1': 0.9,\n",
       " 'beta2': 0.99,\n",
       " 'dict_mult': 32,\n",
       " 'seq_len': 128,\n",
       " 'enc_dtype': 'fp32',\n",
       " 'model_name': 'gelu-2l',\n",
       " 'site': 'z',\n",
       " 'layer': 1,\n",
       " 'device': 'cuda',\n",
       " 'reinit': 'reinit',\n",
       " 'head': 'cat',\n",
       " 'concat_heads': True,\n",
       " 'dead_direction_cutoff': 1e-07,\n",
       " 're_init_every': 50000,\n",
       " 'anthropic_resample_last': 25000,\n",
       " 'resample_factor': 0.01,\n",
       " 'num_resamples': 4,\n",
       " 'wandb_project_name': 'concat-z-gelu-21-l1-lr-sweep-3',\n",
       " 'wandb_entity': 'ckkissane',\n",
       " 'save_state_dict_every': 50000,\n",
       " 'model_batch_size': 512,\n",
       " 'buffer_size': 1572864,\n",
       " 'buffer_batches': 12288,\n",
       " 'act_name': 'blocks.1.attn.hook_z',\n",
       " 'act_size': 512,\n",
       " 'dict_size': 16384,\n",
       " 'name': 'gelu-2l_1_16384_z'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10867/689612026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mauto_encoder_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tinystories-1M-SAES/concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_hf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_encoder_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sae_vis/model_fns.py\u001b[0m in \u001b[0;36mload_from_hf\u001b[0;34m(cls, version)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;36m47\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msecond\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"run1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"run2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mversion_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"run1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m47\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auto_encoder_run = \"tinystories-1M-SAES/concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78\"\n",
    "\n",
    "encoder = AutoEncoder.load_from_hf(auto_encoder_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10867/1866306067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mauto_encoder_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ckkissane/tinystories-1M-SAES/concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_hf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_encoder_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sae_vis/model_fns.py\u001b[0m in \u001b[0;36mload_from_hf\u001b[0;34m(cls, version)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;36m47\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msecond\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"run1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"run2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mversion_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"run1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m47\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auto_encoder_run = \"ckkissane/tinystories-1M-SAES/concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78\"\n",
    "\n",
    "encoder = AutoEncoder.load_from_hf(auto_encoder_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blocks.0.attn.hook_z': HookedSAE(\n",
       "   (hook_sae_input): HookPoint()\n",
       "   (hook_sae_acts_pre): HookPoint()\n",
       "   (hook_sae_acts_post): HookPoint()\n",
       "   (hook_sae_recons): HookPoint()\n",
       "   (hook_sae_error): HookPoint()\n",
       "   (hook_sae_output): HookPoint()\n",
       " ),\n",
       " 'blocks.1.attn.hook_z': HookedSAE(\n",
       "   (hook_sae_input): HookPoint()\n",
       "   (hook_sae_acts_pre): HookPoint()\n",
       "   (hook_sae_acts_post): HookPoint()\n",
       "   (hook_sae_recons): HookPoint()\n",
       "   (hook_sae_error): HookPoint()\n",
       "   (hook_sae_output): HookPoint()\n",
       " )}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

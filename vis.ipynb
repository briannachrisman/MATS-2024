{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab # type: ignore\n",
    "    from google.colab import output\n",
    "    COLAB = True\n",
    "    #%pip install sae-lens==1.3.0 transformer-lens==1.17.0\n",
    "    #%pip install --upgrade sae-lens\n",
    "except:\n",
    "    COLAB = False\n",
    "    from IPython import get_ipython # type: ignore\n",
    "    ipython = get_ipython(); assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "# Imports for displaying vis in Colab / notebook\n",
    "import webbrowser\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading\n",
    "PORT = 8000\n",
    "\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_vis_inline(filename: str, height: int = 850):\n",
    "    '''\n",
    "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
    "    vis has a unique port without having to define a port within the function.\n",
    "    '''\n",
    "    if not(COLAB):\n",
    "        webbrowser.open(filename);\n",
    "\n",
    "    else:\n",
    "        global PORT\n",
    "\n",
    "        def serve(directory):\n",
    "            os.chdir(directory)\n",
    "\n",
    "            # Create a handler for serving files\n",
    "            handler = http.server.SimpleHTTPRequestHandler\n",
    "\n",
    "            # Create a socket server with the handler\n",
    "            with socketserver.TCPServer((\"\", PORT), handler) as httpd:\n",
    "                print(f\"Serving files from {directory} on port {PORT}\")\n",
    "                httpd.serve_forever()\n",
    "\n",
    "        thread = threading.Thread(target=serve, args=(\"/content\",))\n",
    "        thread.start()\n",
    "\n",
    "        output.serve_kernel_port_as_iframe(PORT, path=f\"/{filename}\", height=height, cache_in_notebook=True)\n",
    "\n",
    "        PORT += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "from sae_lens.training.session_loader import LMSparseAutoencoderSessionloader\n",
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "\n",
    "# Set to use 20% of GPU memory, i.e. 8GB on an A100 as ~24 GB is being used to train SAEs\n",
    "# Can remove this if not training on the GPU at the same time\n",
    "# if device == \"cuda\":\n",
    "#     torch.cuda.set_per_process_memory_fraction(0.2, 0)\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# I don't fully understand this but it seems important to avoid some warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# wandb: https://wandb.ai/shehper/gelu-2l-attn-1-sae/reports/gelu-2l-layer-1-attn-heads--Vmlldzo4MDA1NzE4/edit\n",
    "# expcted losses with SAEs are written in front of the labels below\n",
    "ckpt_subfolders = { \n",
    "    0: \"rovi1lwe\", #3.785\n",
    "    1: \"p7113j0v\", #3.807\n",
    "    2: \"rjc53kjg\", #3.768\n",
    "    3: \"hibm6x1l\", #3.738\n",
    "    4: \"4xima76s\", #3.746\n",
    "    5: \"jq26bfpa\", #3.729\n",
    "    6: \"b8e2a9w5\", #3.75\n",
    "    7: \"smfws6mc\" # 3.748\n",
    "}\n",
    "\n",
    "model_name = \"gelu-2l\"\n",
    "hook_point_layer=1\n",
    "hook_point=f\"blocks.{hook_point_layer}.attn.hook_z\"\n",
    "\n",
    "d_in= 64\n",
    "expansion_factor = 32\n",
    "sae_name = f\"{model_name}_{hook_point}_{d_in * expansion_factor}_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59e97046a0e4d589935283af4ac2c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9978251eae6e48df89196757a59a7540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (activation_fn): ReLU()\n",
       "  (hook_sae_in): HookPoint()\n",
       "  (hook_hidden_pre): HookPoint()\n",
       "  (hook_hidden_post): HookPoint()\n",
       "  (hook_sae_out): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_point_head_index = 1 # specify the head index\n",
    "ckpt_dir = os.path.join(\"checkpoints\", \n",
    "                        ckpt_subfolders[hook_point_head_index], \n",
    "                        \"983044096\", # TODO: pick the last ckpt subdir by sorting in\n",
    "                        sae_name)\n",
    "\n",
    "model, saes, activations_loader = LMSparseAutoencoderSessionloader.load_pretrained_sae(path=ckpt_dir,\n",
    "                                                                                        device=device)\n",
    "\n",
    "# print(saes.autoencoders.keys())\n",
    "# saes.autoencoders['gelu-2l_blocks.1.attn.hook_z_2048_'].W_dec\n",
    "\n",
    "sparse_autoencoder = saes.autoencoders[sae_name]\n",
    "sparse_autoencoder.eval()  # prevents error if we're expecting a dead neuron mask for who grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make things consistent with April updates --- normalize activations, normalize W_dec, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 32/32 [00:00<00:00, 123.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from sae_lens.training.activations_store import ActivationsStore\n",
    "\n",
    "n_batches = 2**5 if device == \"cpu\" else 2**10\n",
    "n_prompts = 4096 * 2 if device == \"cpu\" else 4096*6\n",
    "\n",
    "def get_tokens(\n",
    "    activation_store: ActivationsStore,\n",
    "    n_batches_to_sample_from: int = 2**10,\n",
    "    n_prompts_to_select: int = 4096 * 6,\n",
    "):\n",
    "    all_tokens_list = []\n",
    "    pbar = tqdm(range(n_batches_to_sample_from))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        batch_tokens = batch_tokens[torch.randperm(batch_tokens.shape[0])][\n",
    "            : batch_tokens.shape[0]\n",
    "        ]\n",
    "        all_tokens_list.append(batch_tokens)\n",
    "\n",
    "    all_tokens = torch.cat(all_tokens_list, dim=0)\n",
    "    all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]\n",
    "    return all_tokens[:n_prompts_to_select]\n",
    "\n",
    "\n",
    "all_tokens = get_tokens(activations_loader, \n",
    "                        n_batches_to_sample_from=n_batches,\n",
    "                        n_prompts_to_select=n_prompts)  # TODO: keeping it small for cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should I just concatenate all my SAEs?\n",
    "# perhaps the simplest way would be precisely this.\n",
    "# I concatenate all my SAEs, and just implement concatenation of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4983f6c5b62d4612b214542466cf4f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forward passes to cache data for vis:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4834883ec66f4983a83f70435384f994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting vis data from cached data:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Task                                           </span>┃<span style=\"font-weight: bold\"> Time  </span>┃<span style=\"font-weight: bold\"> Pct % </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│ (1) Initialization                             │ 0.01s │ 0.3%  │\n",
       "│ (2) Forward passes to gather model activations │ 0.81s │ 36.9% │\n",
       "│ (3) Computing feature acts from model acts     │ 0.01s │ 0.3%  │\n",
       "│ (4) Getting data for tables                    │ 0.01s │ 0.3%  │\n",
       "│ (5) Getting data for histograms                │ 0.02s │ 0.8%  │\n",
       "│ (6) Getting data for sequences                 │ 1.33s │ 60.2% │\n",
       "│ (7) Getting data for quantiles                 │ 0.03s │ 1.1%  │\n",
       "└────────────────────────────────────────────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTask                                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTime \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│ (1) Initialization                             │ 0.01s │ 0.3%  │\n",
       "│ (2) Forward passes to gather model activations │ 0.81s │ 36.9% │\n",
       "│ (3) Computing feature acts from model acts     │ 0.01s │ 0.3%  │\n",
       "│ (4) Getting data for tables                    │ 0.01s │ 0.3%  │\n",
       "│ (5) Getting data for histograms                │ 0.02s │ 0.8%  │\n",
       "│ (6) Getting data for sequences                 │ 1.33s │ 60.2% │\n",
       "│ (7) Getting data for quantiles                 │ 0.03s │ 1.1%  │\n",
       "└────────────────────────────────────────────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "test_feature_idx_gpt = list(range(10))\n",
    "\n",
    "batch_size = 2 if device == \"cpu\" else 2048\n",
    "minibatch_size_tokens = 16 if device == \"cpu\" else 128\n",
    "\n",
    "feature_vis_config_gpt = SaeVisConfig(\n",
    "    hook_point=hook_point,\n",
    "    features=test_feature_idx_gpt,\n",
    "    batch_size=batch_size,\n",
    "    minibatch_size_tokens=minibatch_size_tokens,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "sae_vis_data_gpt = SaeVisData.create(\n",
    "    encoder=sparse_autoencoder,\n",
    "    model=model, # type: ignore\n",
    "    tokens=all_tokens,  # type: ignore\n",
    "    cfg=feature_vis_config_gpt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcfd6cb58364e7b9327655f819662c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6505380641478c9dbdfd4674db200f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423eaae33dfb41ca8cec2e724b20e8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b75a690d0c14bcc9aa0bc1196434c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dd3e4c41934862aa0a92912528390f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ba997904e442f4ad9773489fa7b0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3edec2bea14c5e95101284939493d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d04a36fb4dd41728cd37de52ae5a81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231af9a14d3e436dbaebe670d037aa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9d3906990f40c6962360a4b6ebe6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(f\"./head{hook_point_head_index}_features\", exist_ok=True)\n",
    "for feature in test_feature_idx_gpt:\n",
    "    filename = f\"./head{hook_point_head_index}_features/{feature}_feature_vis_demo_gpt.html\"\n",
    "    sae_vis_data_gpt.save_feature_centric_vis(filename, feature)\n",
    "    display_vis_inline(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import torch as t\n",
    "from torch import nn, Tensor\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "from typing import Optional, Callable, Union, List, Tuple\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def linear_lr(step, steps):\n",
    "    return (1 - (step / steps))\n",
    "\n",
    "def constant_lr(*_):\n",
    "    return 1.0\n",
    "\n",
    "def cosine_decay_lr(step, steps):\n",
    "    return np.cos(0.5 * np.pi * step / (steps - 1))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AutoEncoderConfig:\n",
    "    n_instances: int\n",
    "    n_input_ae: int\n",
    "    n_hidden_ae: int\n",
    "    l1_coeff: float = 0.5\n",
    "    tied_weights: bool = False\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    W_conv: Float[Tensor, \"d_head n_conv\"]\n",
    "    b_conv: Float[Tensor, \"n_conv\"]\n",
    "\n",
    "    W_enc: Float[Tensor, \"n_conv*d_head n_attn_f\"  ]\n",
    "    b_enc: Float[Tensor, \"n_attn_f\"]\n",
    "\n",
    "    W_dec: Float[Tensor, \"n_attn_f n_conv*d_head\"]\n",
    "    b_dec: Float[Tensor, \"n_conv*d_head\"]\n",
    "\n",
    "    W_deconv: Float[Tensor, \"n_conv d_head\"]\n",
    "    b_deconv: Float[Tensor, \"d_head\"]\n",
    "\n",
    "\n",
    "    def __init__(self, cfg: AutoEncoderConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.W_conv = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.d_head, cfg.n_conv))))\n",
    "        self.W_decconv = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_conv, cfg.d_head))))\n",
    "        self.b_deconv = nn.Parameter(t.zeros(cfg.d_head))\n",
    "        self.b_conv = nn.Parameter(t.zeros(cfg.n_conv))                          \n",
    "\n",
    "\n",
    "        self.W_enc = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_conv * cfg.d_head, cfg.n_attn_f))))\n",
    "        self.W_dec = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_attn_f, cfg.n_conv * cfg.d_head))))\n",
    "\n",
    "        self.b_enc = nn.Parameter(t.zeros(cfg.n_attn_f))\n",
    "        self.b_dec = nn.Parameter(t.zeros( cfg.n_conv * cfg.d_head))\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, h: Float[Tensor, \"batch_size n_head d_head\"]):\n",
    "\n",
    "        # Compute activations\n",
    "        h_cent = h - self.b_deconv\n",
    "        token_feature_acts = einops.einsum(\n",
    "            h_cent, self.W_conv,\n",
    "            \"batch_size n_head d_head, d_head n_conv -> batch_size n_head n_conv\"\n",
    "        )\n",
    "        token_feature_acts = F.relu(acts + self.b_conv)\n",
    "\n",
    "\n",
    "        # Compute activations\n",
    "        acts = (token_feature_acts - self.b_dec).flatten(dim=1)\n",
    "        \n",
    "        # Compute activations\n",
    "        acts = einops.einsum(\n",
    "            acts, self.W_enc,\n",
    "            \"batch_size n_head_n_conv, n_head_n_conv n_attn_f -> batch_size n_attn_f\"\n",
    "        )\n",
    "        attn_feature_acts = F.relu(acts + self.b_enc)\n",
    "\n",
    "        # Compute reconstructed input\n",
    "        token_feature_acts_rec = einops.einsum(\n",
    "            attn_feature_acts, self.W_dec,\n",
    "            \"batch_size n_attn_f, n_attn_f n_head_n_conv -> batch_size n_head_n_conv\"\n",
    "        ) + self.b_dec\n",
    "\n",
    "\n",
    "        token_feature_acts_rec = token_feature_acts_rec.reshape(token_feature_acts.shape)\n",
    "\n",
    "        input_reconstructed = einops.einsum(\n",
    "            token_feature_acts_rec, self.W_deconv\n",
    "            \"batch_size n_head n_conv, n_conv d_head -> batch_size n_head d_head\"\n",
    "        ) + self.b_deconv\n",
    "\n",
    "\n",
    "\n",
    "        # Compute loss, return values\n",
    "        l2_loss = (input_reconstructed - h).pow(2).mean(-1) # shape [batch_size n_instances]\n",
    "        l1_loss_features = token_feature_acts.abs().sum(-1) # shape [batch_size n_instances]\n",
    "        l1_loss_attn = attn_feature_acts.abs().sum(-1) # shape [batch_size n_instances]\n",
    "\n",
    "        loss = (self.cfg.l1_features_coeff * l1_loss_features \n",
    "                + self.cfg.l1_attn_coeff * l1_loss_attn \n",
    "                + l2_loss).mean(0).sum() # scalar\n",
    "\n",
    "        return l1_loss_features, l1_loss_attn, l2_loss, loss, acts, input_reconstructed\n",
    "\n",
    "    @t.no_grad()\n",
    "    def normalize_decoder(self) -> None:\n",
    "        '''\n",
    "        Normalizes the decoder weights to have unit norm. If using tied weights, we we assume W_enc is used for both.\n",
    "        '''\n",
    "        self.W_dec.data = self.W_dec.data / self.W_dec.data.norm(dim=1, keepdim=True)\n",
    "        self.W_deconv.data = self.W_deconv.data / self.W_deconv.data.norm(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "    @t.no_grad()\n",
    "    def resample_neurons(\n",
    "        self,\n",
    "        h: Float[Tensor, \"batch_size n_instances n_hidden\"],\n",
    "        frac_active_in_window: Float[Tensor, \"window n_instances n_hidden_ae\"],\n",
    "        neuron_resample_scale: float,\n",
    "    ) -> None:\n",
    "        '''\n",
    "        Resamples neurons that have been dead for `dead_neuron_window` steps, according to `frac_active`.\n",
    "        '''\n",
    "        pass # See below for a solution to this function\n",
    "\n",
    "    def optimize(\n",
    "        self,\n",
    "        model,\n",
    "        batch_size: int = 1024,\n",
    "        steps: int = 10_000,\n",
    "        log_freq: int = 100,\n",
    "        lr: float = 1e-3,\n",
    "        lr_scale: Callable[[int, int], float] = constant_lr,\n",
    "        neuron_resample_window: Optional[int] = None,\n",
    "        dead_neuron_window: Optional[int] = None,\n",
    "        neuron_resample_scale: float = 0.2,\n",
    "    ):\n",
    "        '''\n",
    "        Optimizes the autoencoder using the given hyperparameters.\n",
    "\n",
    "        This function should take a trained model as input.\n",
    "        '''\n",
    "        if neuron_resample_window is not None:\n",
    "            assert (dead_neuron_window is not None) and (dead_neuron_window < neuron_resample_window)\n",
    "\n",
    "        optimizer = t.optim.Adam(list(self.parameters()), lr=lr)\n",
    "        frac_active_list = []\n",
    "        progress_bar = tqdm(range(steps))\n",
    "\n",
    "        # Create lists to store data we'll eventually be plotting\n",
    "        data_log = {\"W_enc\": [], \"W_dec\": [], \"colors\": [], \"titles\": [], \"frac_active\": []}\n",
    "        colors = None\n",
    "        title = \"no resampling yet\"\n",
    "\n",
    "        for step in progress_bar:\n",
    "\n",
    "            # Normalize the decoder weights before each optimization step\n",
    "            self.normalize_decoder()\n",
    "\n",
    "            # Resample dead neurons\n",
    "            if (neuron_resample_window is not None) and ((step + 1) % neuron_resample_window == 0):\n",
    "                # Get the fraction of neurons active in the previous window\n",
    "                frac_active_in_window = t.stack(frac_active_list[-neuron_resample_window:], dim=0)\n",
    "                # Compute batch of hidden activations which we'll use in resampling\n",
    "                batch = model.generate_batch(batch_size)\n",
    "                h = einops.einsum(batch, model.W, \"batch_size instances features, instances hidden features -> batch_size instances hidden\")\n",
    "                # Resample\n",
    "                colors, title = self.resample_neurons(h, frac_active_in_window, neuron_resample_scale)\n",
    "\n",
    "            # Update learning rate\n",
    "            step_lr = lr * lr_scale(step, steps)\n",
    "            for group in optimizer.param_groups:\n",
    "                group['lr'] = step_lr\n",
    "\n",
    "            # Get a batch of hidden activations from the model\n",
    "            with t.inference_mode():\n",
    "                features = model.generate_batch(batch_size)\n",
    "                h = einops.einsum(features, model.W, \"... instances features, instances hidden features -> ... instances hidden\")\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.zero_grad()\n",
    "            l1_feature_loss, l1_attn_loss, l2_loss, loss, acts, _ = self.forward(h)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate the sparsities, and add it to a list\n",
    "            frac_active = einops.reduce((acts.abs() > 1e-8).float(), \"batch_size instances hidden_ae -> instances hidden_ae\", \"mean\")\n",
    "            frac_active_list.append(frac_active)\n",
    "\n",
    "            # Display progress bar, and append new values for plotting\n",
    "            if step % log_freq == 0 or (step + 1 == steps):\n",
    "                progress_bar.set_postfix(l1_loss=self.cfg.l1_coeff * l1_loss.mean(0).sum().item(), l2_loss=l2_loss.mean(0).sum().item(), lr=step_lr)\n",
    "                data_log[\"W_enc\"].append(self.W_enc.detach().cpu())\n",
    "                data_log[\"W_dec\"].append(self.W_dec.detach().cpu())\n",
    "                data_log[\"colors\"].append(colors)\n",
    "                data_log[\"titles\"].append(f\"Step {step}/{steps}: {title}\")\n",
    "                data_log[\"frac_active\"].append(frac_active.detach().cpu())\n",
    "\n",
    "        return data_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

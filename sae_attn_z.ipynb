{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b2c2e0-c231-46c0-bb16-ead67416db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils import load_our_sae, load_concatenated_sae, import_connor_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7b5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load single head SAEs\n",
    "# head_saes = {}\n",
    "# for hook_point_head_index in [0, 1]:\n",
    "#     model, sae, activations_loader = load_our_sae(hook_point_head_index=hook_point_head_index)\n",
    "#     head_saes[hook_point_head_index] = sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bd1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model, our_concatenated_sae, activations_loader = load_concatenated_sae(l1_coeff=3)\n",
    "connor_sae = import_connor_sae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc72ceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 6\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e248778417d94bc28379a8ab069d75d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eab1a6a982407889d3bf50cc6df142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, single_head_sae, activations_loader = load_our_sae(hook_point_head_index=6, l1_coeff=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f2a7850",
   "metadata": {},
   "source": [
    "## Getting feature activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2b6facef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average l0 0.09824047237634659\n"
     ]
    }
   ],
   "source": [
    "batch_tokens = activations_loader.get_batch_tokens(batch_size=2)\n",
    "B, T = batch_tokens.shape\n",
    "_, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "# why is the reconst loss > 5 instead of expected < 4?\n",
    "out = analyze_sae(single_head_sae)\n",
    "orig_loss, reconst_loss, zero_loss = out[-3], out[-2], out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f3a7e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.9270927906036377, 4.031135559082031, (4.045295715332031,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_loss, reconst_loss, zero_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14919bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 3, head index = 0\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52317d2ad25e4fa29d9fa0977394ee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f647db5247494b9acbbf8099a121d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 3, head index = 1\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df251b6f2a049fb80ba118f670984af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48db924a6bdf4d78aa3360b00729842d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 3, head index = 2\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a4af11f54e403f9ed60e12129ed009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ba6380b72e4e8fb353efc605344505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get model cache\n",
    "import numpy as np\n",
    "num_batches = 20\n",
    "performance = {}\n",
    "#for l1_coeff in [15, 3, 5, 10]:\n",
    "for l1_coeff in [3]:\n",
    "    for hook_point_head_index in range(8):\n",
    "        model, single_head_sae, activations_loader = load_our_sae(hook_point_head_index=hook_point_head_index, \n",
    "                                                                  l1_coeff=l1_coeff)\n",
    "        sparsities, orig_losses, zero_losses, reconst_losses = [], [], [], []\n",
    "        for _ in range(num_batches):\n",
    "            batch_tokens = activations_loader.get_batch_tokens(batch_size=2)\n",
    "            B, T = batch_tokens.shape\n",
    "            _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "            # why is the reconst loss > 5 instead of expected < 4?\n",
    "            out = analyze_sae(single_head_sae)\n",
    "            sparsity, orig_loss, reconst_loss, zero_loss = out[-4], out[-3], out[-2], out[-1]\n",
    "            \n",
    "            sparsities.append(sparsity)\n",
    "            orig_losses.append(orig_loss)\n",
    "            reconst_losses.append(reconst_loss)\n",
    "            zero_losses.append(zero_loss)\n",
    "\n",
    "        performance[(l1_coeff, hook_point_head_index)] = [np.mean(np.array(sparsities)),\n",
    "                                                          np.mean(np.array(orig_losses)), \n",
    "                                                          np.mean(np.array(reconst_losses)), \n",
    "                                                          np.mean(np.array(zero_losses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80338722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7557242050067783\n",
      "1 0.6914234481020729\n",
      "2 0.5121234344043092\n",
      "3 0.8663394780454207\n",
      "4 0.8402239927609593\n",
      "5 1.2360755247713928\n",
      "6 0.8630375144984015\n",
      "7 0.8830042029864679\n"
     ]
    }
   ],
   "source": [
    "good_saes = []\n",
    "for (l1_coeff, head_id) in performance.keys():\n",
    "    orig_, reconst_, zero_ = performance[(l1_coeff, head_id)] \n",
    "    print(head_id, (orig_-reconst_)/(orig_-zero_))\n",
    "    # if reconst_ < zero_:\n",
    "    #     good_saes.append((l1_coeff, head_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07eb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 0): [3.140520143508911, 3.2711434423923493, 3.313365340232849],\n",
       " (3, 1): [3.140520143508911, 3.3660142064094543, 3.4666503369808197],\n",
       " (3, 2): [3.140520143508911, 3.251505768299103, 3.357236695289612],\n",
       " (3, 3): [3.140520143508911, 3.256797742843628, 3.274737274646759],\n",
       " (3, 4): [3.140520143508911, 3.315368390083313, 3.3486173272132875],\n",
       " (3, 5): [3.140520143508911, 3.2167920649051664, 3.2022250473499296],\n",
       " (3, 6): [3.140520143508911, 3.3195857763290406, 3.348003166913986],\n",
       " (3, 7): [3.140520143508911, 3.235272800922394, 3.247827285528183]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f521066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529409"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {(3, 0): [3.140520143508911, 3.2711434423923493, 3.313365340232849],\n",
    "#  (3, 1): [3.140520143508911, 3.3660142064094543, 3.4666503369808197],\n",
    "#  (3, 2): [3.140520143508911, 3.251505768299103, 3.357236695289612],\n",
    "#  (3, 3): [3.140520143508911, 3.256797742843628, 3.274737274646759],\n",
    "#  (3, 4): [3.140520143508911, 3.315368390083313, 3.3486173272132875],\n",
    "#  (3, 5): [3.140520143508911, 3.2167920649051664, 3.2022250473499296],\n",
    "#  (3, 6): [3.140520143508911, 3.3195857763290406, 3.348003166913986],\n",
    "#  (3, 7): [3.140520143508911, 3.235272800922394, 3.247827285528183]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4c55d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "715cd559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0),\n",
       " (5, 0),\n",
       " (10, 0),\n",
       " (15, 0),\n",
       " (3, 1),\n",
       " (5, 1),\n",
       " (10, 1),\n",
       " (15, 1),\n",
       " (3, 2),\n",
       " (5, 2),\n",
       " (10, 2),\n",
       " (15, 2),\n",
       " (3, 3),\n",
       " (5, 3),\n",
       " (10, 3),\n",
       " (15, 3),\n",
       " (3, 4),\n",
       " (5, 4),\n",
       " (10, 4),\n",
       " (15, 4),\n",
       " (3, 5),\n",
       " (5, 5),\n",
       " (10, 5),\n",
       " (15, 5),\n",
       " (3, 6),\n",
       " (5, 6),\n",
       " (10, 6),\n",
       " (15, 6),\n",
       " (3, 7),\n",
       " (5, 7),\n",
       " (10, 7),\n",
       " (15, 7)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(performance.keys(), key=lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "61ddb472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 64])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_head_sae.W_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878b1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91902e60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m (l1_coeff, head_id) \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(performance\u001b[39m.\u001b[39mkeys(), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: (x[\u001b[39m1\u001b[39m], x[\u001b[39m0\u001b[39m])):\n\u001b[1;32m      2\u001b[0m     orig_, reconst_, zero_ \u001b[39m=\u001b[39m performance[(l1_coeff, head_id)] \n\u001b[1;32m      3\u001b[0m     reconst_score \u001b[39m=\u001b[39m (orig_ \u001b[39m-\u001b[39m reconst_)\u001b[39m/\u001b[39m(orig_ \u001b[39m-\u001b[39m zero_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'performance' is not defined"
     ]
    }
   ],
   "source": [
    "for (l1_coeff, head_id) in sorted(performance.keys(), key=lambda x: (x[1], x[0])):\n",
    "    orig_, reconst_, zero_ = performance[(l1_coeff, head_id)] \n",
    "    reconst_score = (orig_ - reconst_)/(orig_ - zero_)\n",
    "    print(f\"head={head_id}, l1={l1_coeff}, reconst score={1-reconst_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good thing is that there is a trend. \n",
    "# Increasing L1-coefficient decreases L0-norm but it increases reconstruction score.\n",
    "# WTF is going on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bf8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "443a49d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 0\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c866bff9ea40a0bf40c56b6eb30a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf012d4610a49bc9d9cf8ec48cdc18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 1\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199d3c6e8cad4bbbaa9db943165da7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9458344f8e402a87660f624ee0dabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 2\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0433c38ce04451ba0c2324c13d97bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4946861fc1bd4077a2350e2f3c5fe6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 3\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f837555f021a4583bb533e9f261767b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33f7a5ce68c4fb3b0ad2e1b3f2c7939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 4\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b55dbdfe30406587ff0205953284b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4798bb521a9046c8a47f222fbb0ae878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 5\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d1b5c049c047d8b71de6fef3575dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a22ad7d0b347ddb1fafdb3c23ebe73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 6\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4f7bb3a8e949d088dac188c5d7275e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e295e763bc8f4771b2339d7f3f79e412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE checkpoint for l1_coeff = 5, head index = 7\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017f4c69f2c5403db244add767f2928e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d002bd09814bd5bd90f86fd8e7c4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating all SAEs from individual attention heads\n"
     ]
    }
   ],
   "source": [
    "# It seems that for the most part L1-coefficient=5 is fine.\n",
    "# Let's check how it does when concatenated\n",
    "_, our_concatenated_sae, _ = load_concatenated_sae(l1_coeff=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction of the concatenated SAE is pretty bad actually. \n",
    "# don't know why!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d31a90eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average l0 7.051319599151611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          ...,\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939]],\n",
       " \n",
       "         [[ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3090,  0.8454, -1.2604,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          ...,\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.7868,  0.2176,  0.1205],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939],\n",
       "          [ 0.3228,  0.8550, -1.2684,  ...,  0.8405,  0.1942,  0.0939]]]),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " tensor(163.0801),\n",
       " tensor(155.7303),\n",
       " tensor(7.3498),\n",
       " 0,\n",
       " 2.6071391105651855,\n",
       " (5.572080612182617,),\n",
       " 6.301891803741455)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sae(our_concatenated_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e947d1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8027027027027028"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.6 - 5.57)/(2.6-6.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd7de529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837837837837838"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5.5 - 2.6)/(6.3-2.6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b7f2cf",
   "metadata": {},
   "source": [
    "connor_dashboards, dashboards, training_scripts/wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9c1ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average l0 16.297653198242188\n",
      "Orig 2.682035207748413\n",
      "reconstr 3.1920928955078125\n",
      "Zero 6.446569919586182\n"
     ]
    }
   ],
   "source": [
    "analyze_sae(connor_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3303242b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13563829787234036"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.68-3.19)/(2.68-6.44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae(\n",
    "        cache[hook_point]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e689028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "\n",
    "# next we want to do a reconstruction test.\n",
    "def analyze_concatenated_sae(sae):\n",
    "    assert sae.cfg.hook_point_head_index is None\n",
    "    hook_point = sae.cfg.hook_point\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss, ghost_grad_loss = sae(\n",
    "        cache[hook_point].view(B, T, -1)\n",
    "    )\n",
    "\n",
    "    l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
    "    # print(\"average l0\", l0.mean().item())\n",
    "\n",
    "    nh, dh = model.cfg.n_heads, model.cfg.d_head\n",
    "    def reconstr_hook(activation, hook, sae_out):\n",
    "        return sae_out.view(B, T, nh, dh)\n",
    "\n",
    "\n",
    "    def zero_abl_hook(activation, hook):\n",
    "        return torch.zeros_like(activation)\n",
    "    \n",
    "    orig_loss = model(batch_tokens, return_type=\"loss\").item()\n",
    "    #print(\"Orig\", orig_loss)\n",
    "    reconst_loss = model.run_with_hooks(\n",
    "                    batch_tokens,\n",
    "                    fwd_hooks=[\n",
    "                        (utils.get_act_name(\"z\", 1), \n",
    "                        partial(reconstr_hook, sae_out=sae_out),)\n",
    "                        ],\n",
    "                    return_type=\"loss\",\n",
    "                    ).item(),\n",
    "    # print(\"reconstr\",reconst_loss)\n",
    "    zero_abl_loss = model.run_with_hooks(\n",
    "            batch_tokens,\n",
    "            return_type=\"loss\",\n",
    "            fwd_hooks=[(utils.get_act_name(\"z\", 1), \n",
    "                        partial(zero_abl_hook))],\n",
    "        ).item()\n",
    "    # print(\"Zero\", zero_abl_loss)\n",
    "    return sae_out, feature_acts, loss, mse_loss, l1_loss, ghost_grad_loss, l0, orig_loss, reconst_loss, zero_abl_loss\n",
    "\n",
    "def analyze_single_head_sae(sae):\n",
    "    assert sae.cfg.hook_point_head_index is not None\n",
    "    hook_point = sae.cfg.hook_point\n",
    "    hook_point_head_index = sae.cfg.hook_point_head_index\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss, ghost_grad_loss = sae(\n",
    "        cache[hook_point][:, :, hook_point_head_index, :]\n",
    "    )\n",
    "\n",
    "    l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
    "    # print(\"average l0\", l0.mean().item())\n",
    "\n",
    "    \n",
    "    def reconstr_hook(activation, hook, sae_out, hook_point_head_index):\n",
    "        activation[:, :, hook_point_head_index, :] = sae_out\n",
    "        return activation\n",
    "\n",
    "    def zero_abl_hook(activation, hook, hook_point_head_index):\n",
    "        activation[:, :, hook_point_head_index, :] = torch.zeros(activation.shape[0], activation.shape[1], activation.shape[3])\n",
    "        # return torch.zeros_like(activation)\n",
    "        return activation\n",
    "    \n",
    "    # print(\"Orig\", model(batch_tokens, return_type=\"loss\").item())\n",
    "    orig_loss = model(batch_tokens, return_type=\"loss\").item()\n",
    "    reconst_loss = model.run_with_hooks(\n",
    "            batch_tokens,\n",
    "            fwd_hooks=[\n",
    "                (utils.get_act_name(\"z\", 1), # TODO: is this correct? how do we specify head number?\n",
    "                partial(reconstr_hook, sae_out=sae_out, hook_point_head_index=hook_point_head_index),)\n",
    "                ],\n",
    "            return_type=\"loss\",\n",
    "            ).item()\n",
    "    # print(\"reconstr\", reconst_loss)\n",
    "\n",
    "    zero_abl_loss = model.run_with_hooks(\n",
    "            batch_tokens,\n",
    "            return_type=\"loss\",\n",
    "            fwd_hooks=[(utils.get_act_name(\"z\", 1), \n",
    "                        partial(zero_abl_hook, hook_point_head_index=hook_point_head_index))],\n",
    "            ).item(),\n",
    "    # print(\"Zero\", zero_abl_loss)\n",
    "    return sae_out, feature_acts, loss, mse_loss, l1_loss, ghost_grad_loss, l0, orig_loss, reconst_loss, zero_abl_loss\n",
    "\n",
    "def analyze_sae(sae):\n",
    "    if sae.cfg.hook_point_head_index is None:\n",
    "        return analyze_concatenated_sae(sae)\n",
    "    else:\n",
    "        return analyze_single_head_sae(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97fef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2f73dd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.1.attn.hook_z'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_act_name(\"z\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97eb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

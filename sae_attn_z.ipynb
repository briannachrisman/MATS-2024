{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4622658e-348f-46a3-a161-bb1ada9674df",
   "metadata": {},
   "source": [
    "The main goal is to produce feature dashboards. \n",
    "\n",
    "But perhaps what needs to be done along the way is other kinds of analysis: for example, norms of decoder columns (as these SAEs are being trained with Anthropic's April update recipe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b2c2e0-c231-46c0-bb16-ead67416db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from sae_lens.training.session_loader import LMSparseAutoencoderSessionloader\n",
    "torch.set_grad_enabled(False)\n",
    "# I don't fully understand this but it seems important to avoid some warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model_name = \"gelu-2l\"\n",
    "hook_point_layer=1\n",
    "hook_point=f\"blocks.{hook_point_layer}.attn.hook_z\"\n",
    "d_in= 64\n",
    "expansion_factor = 32\n",
    "sae_name = f\"{model_name}_{hook_point}_{d_in * expansion_factor}_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7b5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_subfolders = { \n",
    "    0: \"rovi1lwe\", \n",
    "    1: \"p7113j0v\", \n",
    "    2: \"rjc53kjg\", \n",
    "    3: \"hibm6x1l\", \n",
    "    4: \"4xima76s\", \n",
    "    5: \"jq26bfpa\", \n",
    "    6: \"b8e2a9w5\", \n",
    "    7: \"smfws6mc\" \n",
    "}\n",
    "\n",
    "def get_ckpt_dir(hook_point_head_index):\n",
    "    ckpt_dir = os.path.join(\"checkpoints\", \n",
    "                        ckpt_subfolders[hook_point_head_index], \n",
    "                        \"983044096\", \n",
    "                        sae_name)\n",
    "    return ckpt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bd1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 0\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268470613c8f4010b0207a9fde7e5403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090677adf25048a2ab6ef57b93b67a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 1\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee00116039c498bab62677fbabcc224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e078b4b7d1340a5abbb174185fce78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 2\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671ae504f38143898ee017127508c6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200da0eb461e46e68c50a0ba317bbdd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 3\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a3e5583f0349909674c4ec4c73d3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2faffb543141b985ed7bee538b6ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 4\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0117c5d199435abe4d03c25840e388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228ea452af7046438aa782661370087c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 5\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9562e5e33c7740eb9f29d0a19571a941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8372dd84c06e4b4da16922f6419de03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 6\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819ba5d47d6e4ec18447db14d1071b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0fb1caa6e74d73ac9464677418bb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE for head # 7\n",
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7f92e066604c2197a7561052be73bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421e70badceb4b4db71f8589105ae99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load SAEs for each attention head\n",
    "n_heads = 8 \n",
    "saes = {}\n",
    "for hook_point_head_index in range(n_heads):\n",
    "    print(f\"Loading SAE for head # {hook_point_head_index}\")\n",
    "    ckpt_dir = get_ckpt_dir(hook_point_head_index)\n",
    "    model, sae, activations_loader = LMSparseAutoencoderSessionloader.load_pretrained_sae(path=ckpt_dir,\n",
    "                                                                                          device=device)\n",
    "    saes[hook_point_head_index] = sae.autoencoders[sae_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14919bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our SAEs into an SAE that decomposes concatenated activations\n",
    "from sae_lens.training.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.training.sparse_autoencoder import SparseAutoencoder\n",
    "from dataclasses import asdict\n",
    "cat_sae_cfg = asdict(saes[0].cfg)\n",
    "cat_sae_cfg[\"hook_point_head_index\"] = None\n",
    "cat_sae_cfg[\"d_in\"] = 64 * 8\n",
    "cat_sae_cfg[\"d_sae\"] = 2048 * 8\n",
    "cat_sae_cfg = LanguageModelSAERunnerConfig(**cat_sae_cfg)\n",
    "\n",
    "cat_sae = SparseAutoencoder(cat_sae_cfg)\n",
    "\n",
    "# weights are block-diagonal and biases are just concatenations\n",
    "cat_sae.W_dec = torch.nn.Parameter(torch.block_diag(*[sae.W_dec for head, sae in sorted(saes.items())]))\n",
    "cat_sae.W_enc = torch.nn.Parameter(torch.block_diag(*[sae.W_enc for head, sae in sorted(saes.items())]))\n",
    "cat_sae.b_dec = torch.nn.Parameter(torch.cat(tuple(sae.b_dec.data for head, sae in sorted(saes.items()))))\n",
    "cat_sae.b_enc = torch.nn.Parameter(torch.cat(tuple(sae.b_enc.data for head, sae in sorted(saes.items()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31eec43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Connor and Rob's SAE\n",
    "from utils import CR_AutoEncoder\n",
    "from sae_lens.toolkit.pretrained_saes import convert_connor_rob_sae_to_our_saelens_format\n",
    "auto_encoder_run = \"concat-z-gelu-21-l1-lr-sweep-3/gelu-2l_L1_Hcat_z_lr1.00e-03_l12.00e+00_ds16384_bs4096_dc1.00e-07_rie50000_nr4_v78\"\n",
    "cr_sae = CR_AutoEncoder.load_from_hf(auto_encoder_run)\n",
    "# New sae-lens state dict requires scaling factor which CR'SAE did not have\n",
    "cr_sae_state_dict = cr_sae.state_dict()\n",
    "cr_sae_state_dict[\"scaling_factor\"] = torch.ones(cr_sae.cfg[\"dict_size\"],)\n",
    "\n",
    "cr_sae = convert_connor_rob_sae_to_our_saelens_format(\n",
    "    state_dict=cr_sae_state_dict,\n",
    "    config=cr_sae.cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d791e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation store can give us tokens.\n",
    "batch_tokens = activations_loader.get_batch_tokens(batch_size=8) \n",
    "B, T = batch_tokens.shape\n",
    "_, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "# # Use the SAE\n",
    "# sae_out, feature_acts, loss, mse_loss, l1_loss, ghost_grad_loss\n",
    "_, cat_feature_acts, _, _, _, _ = cat_sae(\n",
    "    cache[cat_sae.cfg.hook_point].view(B, T, -1)\n",
    ") \n",
    "\n",
    "# activation store can give us tokens.\n",
    "_, cr_feature_acts, _, _, _, _ = cr_sae(\n",
    "    cache[cr_sae.cfg.hook_point].view(B, T, -1)\n",
    ") \n",
    "\n",
    "del cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c8664a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_corr_matrix\n",
    "feature_id = 99\n",
    "corr_matrix = compute_corr_matrix(cr_feature_acts[:, :, 99].view(-1)[:, None], cat_feature_acts.view(-1, cat_feature_acts.shape[-1]))\n",
    "corr_matrix = corr_matrix.squeeze(dim=0)\n",
    "corr_matrix[corr_matrix.isnan()] = float('-inf')\n",
    "\n",
    "k = 20\n",
    "values, indices = corr_matrix.topk(k=k)\n",
    "for val, id in zip(values, indices):\n",
    "    print(f\"corr val: {val:.2f}, head # {id // 2048}, feature # {id % 2048}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
